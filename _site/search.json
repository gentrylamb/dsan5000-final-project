[
  {
    "objectID": "technical-details/progress-log.html",
    "href": "technical-details/progress-log.html",
    "title": "Progress log",
    "section": "",
    "text": "Use this page to track your progress and keep a log of your contributions to the project, please update this each time you work on your project, it is generally a good habit to adopt.\nIf you are working as a team, at the end, you can duplicate the project and add it to your individual portfolio websites. If you do, you MUST retain attribution to your teammates. Removing attribution would constitute plagiarism."
  },
  {
    "objectID": "technical-details/progress-log.html#to-do",
    "href": "technical-details/progress-log.html#to-do",
    "title": "Progress log",
    "section": "To-do",
    "text": "To-do\n\nExplore possible topics by brainstorming with GPT\nwrite a technical methods sections for K-means\nwrite a technical methods sections for PCA\n\n… etc"
  },
  {
    "objectID": "technical-details/progress-log.html#member-1",
    "href": "technical-details/progress-log.html#member-1",
    "title": "Progress log",
    "section": "Member-1:",
    "text": "Member-1:\nGentry Lamb\nWeekly project contribution log:\n11-21-2024\n\nCoordinate with team member to set up first project meeting\n\n11-25-2024\n\nBegin working on data collection and researching use of Selenium\n\n12-01-2024\n\nWrite data collection code\n\n12-06-2024\n\nWrite literature review and put together the landing page\n\n12-07-2024\n\nUpdate data collection code to include distances\nWrite data cleaning code\nStart writing EDA code\n\n12-08-2024\n\nComplete writing EDA code and start on Unsupervised Learning Code\n\n12-09-2024\n\nComplete writing Unsupervised Learning Code and start on write-up\n\n12-10-2024\n\nComplete write-up for Unsupervised Learning\nRestructure/Format all technical details page\nComplete all code and write-ups, begin working on non-technical report\n\n12-11-2024"
  },
  {
    "objectID": "technical-details/progress-log.html#member-2",
    "href": "technical-details/progress-log.html#member-2",
    "title": "Progress log",
    "section": "Member-2:",
    "text": "Member-2:\nChase Clemence\nWeekly project contribution log:\n11-21-2024\n\nAttend first group meeting\n\n12-06-2024\n\nComplete literature review and put together the landing page\n\n12-07-2024\n\nWrote technical details for data collection\nRefined the landing page to include more information\nWrote technical details for data cleaning\n\n12-08-2024\n\nWrote technical details for EDA\nCoded up a lot of the supervised learning portion\n\n12-08-2024\n\nFinished the code for supervised learning\n\n12-10-2024\n\nCompleted the technical details for supervised learning"
  },
  {
    "objectID": "report/report.html",
    "href": "report/report.html",
    "title": "Analyzing Bike Routes in Washington, DC:",
    "section": "",
    "text": "Exploring a new city can be an overwhelming experience, especially when navigating its unique traditions, attractions, and outdoor activities. For avid biking enthusiasts, this challenge is heightened by the need to find suitable bike paths to explore. Questions like Which trails offer the best scenery around the city? and Which paths are most practical for commuting, shopping, or other daily activities? naturally arise when diving into the biking landscape of an unfamiliar area.\nEven for those less passionate about cycling, services like Lime, Capital Bikeshare, and others have made eBikes widely accessible, offering a convenient and sustainable way to explore the city. Biking, whether as a recreational activity or a mode of transportation, is a vital aspect of urban culture. Beyond its practical benefits, cycling also contributes to reducing carbon emissions, playing a critical role in a city’s environmental sustainability efforts.\nFor residents and visitors of Washington, DC, biking is an integral part of city life. However, identifying bike trails that align with personal goals—whether for leisure, fitness, or utility—can be a daunting task. This study aims to address that challenge by clustering bike trails based on their inherent qualities and predicting characteristics for new or unexplored paths.\nWe focused on a variety of trail attributes to inform our analysis. These included ratings for terrain difficulty, traffic levels, and scenic beauty. Additionally, we considered sentiment analysis, trail distances, and structural aspects such as whether a trail forms a loop. By leveraging these characteristics, our goal is to group similar bike paths together, providing users with actionable insights into which trails best meet their needs."
  },
  {
    "objectID": "report/report.html#introduction",
    "href": "report/report.html#introduction",
    "title": "Analyzing Bike Routes in Washington, DC:",
    "section": "",
    "text": "Exploring a new city can be an overwhelming experience, especially when navigating its unique traditions, attractions, and outdoor activities. For avid biking enthusiasts, this challenge is heightened by the need to find suitable bike paths to explore. Questions like Which trails offer the best scenery around the city? and Which paths are most practical for commuting, shopping, or other daily activities? naturally arise when diving into the biking landscape of an unfamiliar area.\nEven for those less passionate about cycling, services like Lime, Capital Bikeshare, and others have made eBikes widely accessible, offering a convenient and sustainable way to explore the city. Biking, whether as a recreational activity or a mode of transportation, is a vital aspect of urban culture. Beyond its practical benefits, cycling also contributes to reducing carbon emissions, playing a critical role in a city’s environmental sustainability efforts.\nFor residents and visitors of Washington, DC, biking is an integral part of city life. However, identifying bike trails that align with personal goals—whether for leisure, fitness, or utility—can be a daunting task. This study aims to address that challenge by clustering bike trails based on their inherent qualities and predicting characteristics for new or unexplored paths.\nWe focused on a variety of trail attributes to inform our analysis. These included ratings for terrain difficulty, traffic levels, and scenic beauty. Additionally, we considered sentiment analysis, trail distances, and structural aspects such as whether a trail forms a loop. By leveraging these characteristics, our goal is to group similar bike paths together, providing users with actionable insights into which trails best meet their needs."
  },
  {
    "objectID": "report/report.html#objective",
    "href": "report/report.html#objective",
    "title": "Analyzing Bike Routes in Washington, DC:",
    "section": "Objective",
    "text": "Objective\nThe primary goal of this research is to analyze and categorize the bike trails in Washington, DC, to provide valuable insights that help cyclists make informed decisions about their routes. By examining key characteristics of the trails, such as distance, terrain difficulty, traffic conditions, and scenic value, we aim to create a comprehensive understanding of the biking infrastructure in the city. The study specifically focuses on the objectives of trail clustering and predicting route attributes.\nBy employing different clustering algorithms, we attempt to group bike trails with similar characteristics such as distance, terrain, traffic and more. This will allow cyclists to easily identify trails that best match their preferences, whether they seek leisurely recreation or a physically demanding workout. Beyond just cyclists, grouping data can be used by city planners in addressing gaps in trail diversity when expanding trails to new areas. For example, if there are few trails catering to beginners with flat terrain and low traffic, planners can prioritize adding such routes to balance the network and make cycling more accessible.\nWe transitioned from clustering techniques to a focus on supervised learning methods with the objective of accurately predicting key qualities of bike trails. Specifically, we utilized decision trees to achieve this goal. Predictive modeling in this context offers significant potential to enhance the overall biking experience and address various practical needs. For instance, an effective model can predict trail sentiment — a measure that provides insight into factors such as the level of tourism or crowding on a trail. Cyclists seeking quieter routes can use these predictions to identify less busy trails, thereby tailoring their experience to personal preferences. Additionally, supervised learning can provide insights into the structural characteristics of a trail, such as whether it forms a loop. This type of information not only improves a cyclist’s understanding of a trail but also contributes to safety by helping riders make more informed decisions about their routes. Overall, our objective is to leverage supervised learning techniques to deliver actionable insights that optimize the biking experience and enhance trail accessibility, safety, and enjoyment."
  },
  {
    "objectID": "report/report.html#key-findings",
    "href": "report/report.html#key-findings",
    "title": "Analyzing Bike Routes in Washington, DC:",
    "section": "Key Findings",
    "text": "Key Findings"
  },
  {
    "objectID": "report/report.html#clustering",
    "href": "report/report.html#clustering",
    "title": "Analyzing Bike Routes in Washington, DC:",
    "section": "Clustering",
    "text": "Clustering\n\nClustering results were subtle, and clear, actionable groupings were not identified.\nK-Means showed the most promise, though the clusters lacked obvious interpretability.\nResults suggest that current features may not fully capture trail distinctions; additional data could improve insights.\nIncorporating user feedback or geospatial data might enhance the clustering process and provide more actionable results.\n\n\nPredicting\n\nA simple linear model predicted sentiment with roughly 86% success. However, it was deemed a poor fit for the data, having an R^2 value of 0.03.\nUsing a more advanced model, we successfully predicted the sentiment of previously unseen trails with over 95% accuracy (equivalent to a 4.7% error rate).\nPredicting whether a trail forms a loop proved more challenging, with the model achieving an accuracy of around 78%.\nLastly, predicting the state in which a trail begins was particularly difficult, with the model reaching only 44% accuracy."
  },
  {
    "objectID": "report/report.html#methodology-overview",
    "href": "report/report.html#methodology-overview",
    "title": "Analyzing Bike Routes in Washington, DC:",
    "section": "Methodology Overview",
    "text": "Methodology Overview\n\nData\nTo gain a comprehensive understanding of bike trails in Washington, DC, we gathered data from BikeWashington.org, a detailed resource for bike trails in the region. The site includes a table of routes with information on names, descriptions, distances, and ratings for terrain, traffic, and scenery. Using web scraping techniques with browser automation tools, we efficiently processed this information for analysis, resulting in a dataset of 43 unique routes with six key attributes.\nThe dataset underwent a cleaning process to address redundant columns, missing values, and inconsistent category formats. Additionally, binary features were created, and sentiment analysis of route descriptions was performed, expanding the dataset to 15 attributes.\nExploratory Data Analysis (EDA) was conducted as the final step in data preparation. Techniques such as descriptive statistics, density plots, frequency analysis, and count plots were employed to understand the data better. EDA provided valuable insights into the dataset’s structure and helped identify relationships and patterns critical for subsequent clustering and modeling tasks.\n\n\nUnsupervised Learning\nClustering the bike trails involved multiple steps to uncover patterns and groupings within the dataset, leveraging unsupervised learning techniques. Initially, we applied dimensionality reduction methods, such as Principal Component Analysis (PCA) and t-Distributed Stochastic Neighbor Embedding (t-SNE), to simplify the dataset while preserving its essential structure. PCA helped identify the optimal number of dimensions by capturing variance, whereas t-SNE provided a more nuanced visualization of potential clusters by maintaining local similarities. Both techniques informed the subsequent clustering steps, allowing us to visualize the data in reduced dimensions and better understand its structure.\nThree primary clustering algorithms were then employed to group similar bike trails: K-Means, DBSCAN, and Hierarchical Clustering. K-Means, a partitioning method, was optimized using the Elbow and Silhouette methods to determine the appropriate number of clusters. This approach provided well balanced groups that logically appeared the best. The clusters formed by K-Means generally aligned with routes that shared common features, such as similar distances or ratings. The plot below illustrates the eight clusters formed by K-Means, projected onto the 2-D t-SNE space for ease of visualization.\n\nDBSCAN, a density-based clustering method, allowed us to detect clusters of trails based on proximity and density, making it particularly useful for identifying outliers or trails that do not fit well into other groupings. While this ability is beneficial for excluding irrelevant data, it resulted in an uneven distribution of clusters. This highlights the sparsity of our data set, as we have a 15 dimensional vector space and only 43 points to fill it. Below displays the DBSCAN clusters represented in a 2-D space. Note that purple points represent “noise” or unassigned data in the DBSCAN algorithm.\n\nFinally, Hierarchical Clustering was implemented to create a framework of the groups clusters belonged to. Specifically, we used agglomerative clustering, or “bottom-up”, where each data point starts as its own cluster and is progressively merged with others to form larger clusters until all data points are grouped. This resulted in 18 different clusters as seen in the plot below.\n\n\n\nSupervised Learning\nLinear regression can be thought of as drawing a line of best fit through a set of data points to uncover the most accurate relationship between variables. It is one of the simplest and most interpretable models for making predictions. Using data from 43 bike trails in the DMV area, we explored the predictive power of a multiple linear regression model. Specifically, we aimed to predict the sentiment of a trail (the dependent variable) based on 10 independent variables: terrain rating, traffic rating, scenery rating, normalized distance in miles, unpaved, flat, workout, park, river, and loop. After training the model on 34 observations, we assessed its performance by evaluating both the error and the goodness-of-fit. While the model predicted trail sentiment reasonably well, it ultimately failed to capture the complexity of the data, making it a poor overall fit.\nIn contrast, regression trees rely on decision-based rules to create a branching structure of yes/no responses, leading to a specific outcome. We used a regression tree to predict sentiment using the same 10 independent variables. After training the tree on 34 observations and testing it on unseen data, we optimized its structure by experimenting with different parameters. The resulting tree outperformed the linear regression model, improving prediction accuracy by nearly 10%, demonstrating the superiority of regression trees in this context.\nTo predict whether a bike trail was a loop, we used a binary classification tree. Classification trees operate similarly to regression trees but predict discrete outcomes — in this case, whether a trail is a loop (1) or not (0). We optimized the tree’s parameters and trained it on 80% of the dataset. While the model achieved reasonable accuracy, there was significant room for improvement, indicating that additional data or alternative approaches might enhance performance.\nFinally, we used a multiclass classification tree to predict the state where each bike trail begins. Unlike binary classification trees, multiclass trees predict one of several possible categories — in this case, four unique state labels in our dataset. Following the same procedure as before, we optimized the tree’s parameters and trained it on 80% of the data. However, this model performed poorly in predicting the correct state, only slightly surpassing random guessing. This outcome highlighted the complexity of the task and the limitations of the current dataset and approach."
  },
  {
    "objectID": "report/report.html#societal-implications",
    "href": "report/report.html#societal-implications",
    "title": "Analyzing Bike Routes in Washington, DC:",
    "section": "Societal Implications",
    "text": "Societal Implications\nThe results of the clustering methods revealed some groupings, but they were not particularly clear or immediately informative. Of the three methods used, K-Means produced the most interpretable results, with clusters aligning to some extent with trail features. However, the distinctions between clusters were subtle, and no definitive or obvious patterns emerged that could clearly segment trails into well-defined categories. While K-Means provided a structured grouping, these results should be approached cautiously, as the boundaries between clusters were not always intuitive or meaningful. This lack of clarity suggests that the features used in this analysis may not fully capture the nuances of trail characteristics or user preferences. As a result, the clustering outputs should be taken with a grain of salt, as they may not provide actionable insights without further refinement or additional data. While K-Means performed relatively well, the overall findings highlight the need for caution when interpreting clustering results in this context."
  },
  {
    "objectID": "report/report.html#call-to-action",
    "href": "report/report.html#call-to-action",
    "title": "Analyzing Bike Routes in Washington, DC:",
    "section": "Call to Action",
    "text": "Call to Action"
  },
  {
    "objectID": "report/report.html#conclusion",
    "href": "report/report.html#conclusion",
    "title": "Analyzing Bike Routes in Washington, DC:",
    "section": "Conclusion",
    "text": "Conclusion"
  },
  {
    "objectID": "technical-details/unsupervised-learning/overview.html",
    "href": "technical-details/unsupervised-learning/overview.html",
    "title": "Introduction and Motivation",
    "section": "",
    "text": "Introduction and Motivation\nThe primary objective of this analysis is to explore and identify meaningful groupings within a dataset of bike routes in Washington, DC, based on features like distance, ratings, sentiment, and route descriptions. By applying clustering techniques, we aim to uncover hidden patterns that can offer insights into the structure of bike routes across the city. To aid in visualizing these patterns, we also conduct dimensionality reduction using PCA and t-SNE. These methods help reduce the complexity of the high-dimensional data, allowing for clearer visualization and interpretation of the clustering results. The analysis involves testing three clustering algorithms—K-Means, DBSCAN, and Agglomerative Clustering—and comparing their performance in terms of cluster quality and relevance to the underlying features of the routes. Ultimately, the goal is to identify clusters that can inform urban planning and biking route optimization in a practical context.\n\n\nOverview of Methods\nThis analysis employs three clustering algorithms to identify groups within the bike routes dataset, along with dimensionality reduction techniques to visualize the results effectively:\n\nPCA (Principal Component Analysis) and t-SNE (t-Distributed Stochastic Neighbor Embedding): Used to reduce the dimensionality of the data. PCA compresses the features into principal components, capturing the most important variance in the dataset, while t-SNE further reduces the data to two dimensions, making it easier to visualize the clusters.\nK-Means Clustering: K-Means is a partitioning-based algorithm that assigns data points into a predefined number of clusters by iterating between assigning points to the nearest centroid and updating the centroids based on these assignments. The number of clusters (n_clusters) is determined by evaluating the silhouette score, a metric that measures how well-separated the clusters are.\nDBSCAN (Density-Based Spatial Clustering of Applications with Noise): DBSCAN is a density-based clustering algorithm that groups data points based on their proximity to each other and the density of their surroundings. Unlike K-Means, DBSCAN does not require specifying the number of clusters in advance. It relies on two hyperparameters: eps (the maximum distance between two points to be considered neighbors) and min_samples (the minimum number of points required to form a cluster). DBSCAN also identifies noise points, which are labeled as -1.\nAgglomerative Clustering: Agglomerative Clustering is a hierarchical method that builds clusters by iteratively merging the closest pairs of clusters. The number of clusters (n_clusters) is specified as a hyperparameter, and the algorithm outputs cluster labels for each data point. Agglomerative Clustering produces a hierarchical tree (dendrogram) that shows how clusters are merged, which can help understand the relationships between different groupings."
  },
  {
    "objectID": "technical-details/eda/overview.html",
    "href": "technical-details/eda/overview.html",
    "title": "Introduction and Motivation",
    "section": "",
    "text": "With our processed data, we created numerous visualizations to uncover the underlying patterns in the bike trail dataset. Most of the analyses focused on univariate relationships, though we also explored some bivariate relationships, particularly between trail ratings. Additionally, we examined the potential for clustering by comparing mileage with sentiment, using the trail’s scenery score as a color-coded feature."
  },
  {
    "objectID": "technical-details/eda/overview.html#univariate-analysis",
    "href": "technical-details/eda/overview.html#univariate-analysis",
    "title": "Introduction and Motivation",
    "section": "Univariate Analysis",
    "text": "Univariate Analysis\n\nNumerical Variables\nWe analyzed the distributions of numerical variables, particularly mileage and sentiment:\n\nMileage: A discrete variable, categorized into bins for easier analysis. The distribution shows that most trails fall within the 10-120 mile range, with a slight right skew indicating a few longer trails (up to 175 miles).\nSentiment: A continuous variable analyzed using Kernel Density Estimation. The distribution reveals that most sentiments are positive, concentrated within the 0-0.8 range. The bimodal nature of the distribution indicates peaks around 0 and 0.6.\n\n\n\nCategorical Variables\nBar charts helped us visualize the distributions of trail ratings—terrain, traffic, and scenery:\n\nTerrain: The only rating using the full range (1-5). Most trails are rated 3, with fewer trails rated 4 or 5.\nTraffic: Ranges from 1-4, with most trails rated 2 or 3.\nScenery: Restricted to scores of 1-3, with the majority of trails rated 1 or 2."
  },
  {
    "objectID": "technical-details/eda/overview.html#bivariate-analysis",
    "href": "technical-details/eda/overview.html#bivariate-analysis",
    "title": "Introduction and Motivation",
    "section": "Bivariate Analysis",
    "text": "Bivariate Analysis\n\nHeatmaps\nWe explored relationships between trail ratings using heatmaps:\n\nTerrain vs. Scenery: The combination of terrain (3) and scenery (1) is the most frequent.\nTerrain vs. Traffic: The most common combination is when both ratings are 3.\nTraffic vs. Scenery: Most common combinations are scenery (1) and traffic (2) as well as scenery (2) and traffic (3).\n\n\n\nCorrelation Analysis\nA correlation matrix comparing mileage, sentiment, and the three ratings showed no strong correlations. However, sentiment and terrain rating had the highest correlation, suggesting that challenging terrains might lead to more negative sentiments."
  },
  {
    "objectID": "technical-details/eda/overview.html#multivariate-analysis",
    "href": "technical-details/eda/overview.html#multivariate-analysis",
    "title": "Introduction and Motivation",
    "section": "Multivariate Analysis",
    "text": "Multivariate Analysis\nTo identify potential clusters, we visualized distance vs. sentiment, color-coded by the scenery score and annotated with the loop variable (loop vs. non-loop trails). The scatter plot revealed:\n\nNo clear clusters based on distance and sentiment.\nScenery scores often grouped closely, with no discernible differences between loop and non-loop trails."
  },
  {
    "objectID": "technical-details/eda/overview.html#statistical-tests",
    "href": "technical-details/eda/overview.html#statistical-tests",
    "title": "Introduction and Motivation",
    "section": "Statistical Tests",
    "text": "Statistical Tests\nWe conducted a series of statistical tests to analyze the relationships between numerical, binary, and categorical features in our dataset. Below, we outline the methodology and results for each type of test:\n\nKolmogorov-Smirnov Test\nTo assess the normality of the numerical variables (mileage and sentiment), we used the Kolmogorov-Smirnov test. The results indicated that both variables appear to be normally distributed:\n\nSentiment: p-value ≈ 0.198\nMileage: p-value ≈ 0.091\n\nSince the p-values are greater than 0.05, we fail to reject the null hypothesis, concluding that both variables are likely normally distributed.\n\n\nt-Tests (Continuous vs. Binary Variables)\nWe performed t-tests to compare the means of numerical variables (sentiment and mileage) across each binary variable in the dataset. For every combination:\n\nThe p-values were greater than 0.05.\nThis indicates that we fail to reject the null hypothesis, suggesting no significant differences in means between the numerical variables from the lens of the the binary features.\n\n\n\nChi-Squared Tests (Categorical Features)\nWe used chi-squared tests to examine the independence between all pairs of categorical variables (traffic, terrain, scenery, state1, and state2). The results revealed statistically significant associations for the following pairs:\n\nTraffic vs. Terrain: p-value ≈ 0.039\nTerrain vs. State1: p-value ≈ 0.033\nState1 vs. State2: p-value ≈ 5.61e-11\n\nFor these pairs, we reject the null hypothesis at a significance level of 0.05, concluding that these categorical variables are not independent. All other pairs yielded p-values greater than 0.05, indicating no evidence of dependence.\n\n\nANOVA Tests (Continuous vs. Categorical Variables)\nWe conducted ANOVA tests to compare the means of continuous variables (sentiment and mileage) across the levels of categorical variables. Notable results include:\n\nSentiment across Terrain Levels: p-value ≈ 0.028\n\nThis suggests a significant difference in sentiment means across terrain categories, leading us to reject the null hypothesis.\n\nSentiment across Traffic Levels: p-value ≈ 0.059\n\nAlthough this result is close, it does not meet the 0.05 significance threshold.\n\n\nFor all other tests, the p-values were greater than 0.05, indicating no significant differences in means across the levels of the binary or categorical variables.\n\n\nStatistical Summary\n\nNormality (Kolmogorov-Smirnov): Both sentiment and mileage are likely normally distributed.\nt-Tests: No significant differences in means between numerical and binary variables.\nChi-Squared Tests: Significant associations observed for traffic vs. terrain, terrain vs. state1, and state1 vs. state2.\nANOVA: Significant differences in sentiment across terrain levels; no other significant results.\n\nThese findings provide insights into the relationships within the dataset and guide further analysis."
  },
  {
    "objectID": "technical-details/eda/overview.html#key-insights",
    "href": "technical-details/eda/overview.html#key-insights",
    "title": "Introduction and Motivation",
    "section": "Key Insights",
    "text": "Key Insights\n\nSentiment is generally positive, with a bimodal distribution.\nMost trails are relatively short (10-120 miles), though a few exceed 175 miles.\nTerrain ratings are diverse, but traffic and scenery ratings have narrower ranges.\nNo strong correlations exist between numerical or categorical variables.\nDistinct clusters are not evident based on distance, sentiment, or scenery."
  },
  {
    "objectID": "technical-details/eda/overview.html#conclusion-and-next-steps",
    "href": "technical-details/eda/overview.html#conclusion-and-next-steps",
    "title": "Introduction and Motivation",
    "section": "Conclusion and Next Steps",
    "text": "Conclusion and Next Steps\nThe EDA revealed limited patterns for effectively grouping trails. While the correlation matrix and scatter plots showed minimal relationships, the insights into distributions and rating combinations inform our understanding of the data. These findings will guide the next steps:\n\nModeling: Explore whether machine learning can identify subtle patterns.\nFeature Engineering: Consider different variable relationships or transformations to improve clustering potential.\n\nAll visualizations, including heatmaps, bar charts, and scatter plots, as well as statistical testing outputs, can be found in the Code section below."
  },
  {
    "objectID": "technical-details/data-collection/closing.html",
    "href": "technical-details/data-collection/closing.html",
    "title": "Summary",
    "section": "",
    "text": "During the data cleaning process, several technical challenges were encountered. These included overly generalized HTML formatting that did not ID or name any components in the site. Addressing these issues required extremely specific custom regular expressions and manual inspection to ensure data accuracy. Another challenge was getting the webdriver to work on a WSL connected device. There were several issues with getting Selenium to properly initialize communication with Google Chrome and the installed driver.\n\n\n\nThe data cleaning process has provided a strong foundation for the analytical components of this project. Key technical accomplishments include the successful extraction, transformation, and storing of the data. The next step for us is to clean the data and add relevant features as needed for analysis down the road.\nFuture work will focus on:\n\nExpanding the Dataset: Incorporating additional data sources to improve trail coverage and diversity.\nFeature Engineering: Developing more advanced features, such as weather conditions, trail popularity, or proximity to public transit, to enhance model performance.\nUser Feedback Integration: Leveraging feedback from local riders to validate and refine trail ratings and recommendations.\nScaling Solutions: Automating the data cleaning pipeline for integration with larger datasets or real-time updates.\n\nBy continuing to refine and augment the dataset, this project aims to deliver actionable insights and tailored recommendations to the biking community."
  },
  {
    "objectID": "technical-details/data-collection/closing.html#challenges",
    "href": "technical-details/data-collection/closing.html#challenges",
    "title": "Summary",
    "section": "",
    "text": "During the data cleaning process, several technical challenges were encountered. These included overly generalized HTML formatting that did not ID or name any components in the site. Addressing these issues required extremely specific custom regular expressions and manual inspection to ensure data accuracy. Another challenge was getting the webdriver to work on a WSL connected device. There were several issues with getting Selenium to properly initialize communication with Google Chrome and the installed driver."
  },
  {
    "objectID": "technical-details/data-collection/closing.html#conclusion-and-future-steps",
    "href": "technical-details/data-collection/closing.html#conclusion-and-future-steps",
    "title": "Summary",
    "section": "",
    "text": "The data cleaning process has provided a strong foundation for the analytical components of this project. Key technical accomplishments include the successful extraction, transformation, and storing of the data. The next step for us is to clean the data and add relevant features as needed for analysis down the road.\nFuture work will focus on:\n\nExpanding the Dataset: Incorporating additional data sources to improve trail coverage and diversity.\nFeature Engineering: Developing more advanced features, such as weather conditions, trail popularity, or proximity to public transit, to enhance model performance.\nUser Feedback Integration: Leveraging feedback from local riders to validate and refine trail ratings and recommendations.\nScaling Solutions: Automating the data cleaning pipeline for integration with larger datasets or real-time updates.\n\nBy continuing to refine and augment the dataset, this project aims to deliver actionable insights and tailored recommendations to the biking community."
  },
  {
    "objectID": "technical-details/unsupervised-learning/main.html",
    "href": "technical-details/unsupervised-learning/main.html",
    "title": "Unsupervised Learning",
    "section": "",
    "text": "The primary objective of this analysis is to explore and identify meaningful groupings within a dataset of bike routes in Washington, DC, based on features like distance, ratings, sentiment, and route descriptions. By applying clustering techniques, we aim to uncover hidden patterns that can offer insights into the structure of bike routes across the city. To aid in visualizing these patterns, we also conduct dimensionality reduction using PCA and t-SNE. These methods help reduce the complexity of the high-dimensional data, allowing for clearer visualization and interpretation of the clustering results. The analysis involves testing three clustering algorithms—K-Means, DBSCAN, and Agglomerative Clustering—and comparing their performance in terms of cluster quality and relevance to the underlying features of the routes. Ultimately, the goal is to identify clusters that can inform urban planning and biking route optimization in a practical context."
  },
  {
    "objectID": "technical-details/unsupervised-learning/main.html#part-1-dimensionality-reduction",
    "href": "technical-details/unsupervised-learning/main.html#part-1-dimensionality-reduction",
    "title": "Unsupervised Learning",
    "section": "Part 1: Dimensionality Reduction",
    "text": "Part 1: Dimensionality Reduction\nIn this section we explore the effectiveness of dimensionality reducing techniques.\n\nPCA\nFirst we prepared the data by removing non-numeric columns, leaving only numerical features in numeric_df. The remaining data is then standardized with StandardScaler to ensure all features have a mean of 0 and a standard deviation of 1. This standardization is necessary because PCA can be sensitive to the scale of the data. PCA is applied to the scaled data without specifying the number of components, resulting in all possible components being computed. The pca.fit_transform method transforms the data into the new principal component space. The explained_variance_ratio_ attribute of the PCA object provides the proportion of variance explained by each component. Then we visualize the cumulative sum of this explained variance against the number of PCA components to identify a “cutoff” point. The line is pretty constant but we believe 90% is a sufficient portion, so we conclude that 7 principal components is sufficient.\n\n# Standardize the data (often helps with clustering)\nnumeric_df = df.drop(columns=['name','state1','state2'])\nscaled_df = StandardScaler().fit_transform(numeric_df)\n\n# Apply PCA\npca = PCA()\n# apply pca to scaled data\npca_result = pca.fit_transform(scaled_df)\n\n# plot explained variance\nexplained_variance_ratio = pca.explained_variance_ratio_\n# plot number of components against cumulative explained variance\nplt.plot(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio.cumsum(), marker='o')\n# label the plot\nplt.title('Cumulative Explained Variance by PCA Components')\nplt.xlabel('Number of Components')\nplt.ylabel('Cumulative Explained Variance')\nplt.show()\n\n\n\n\n\n\n\n\nNext, since we can’t visualize what something is looks like in 7-dimensions, we will apply the first 2 components to visualize the data in two dimensions. We plot this 2D visualization, where The x-axis and y-axis correspond to the first and second principal components. Points are color-coded based on the sentiment column from the original dataset, allowing for the identification of patterns or clusters related to sentiment. This 2D visualization provides an intuitive way to observe structure and relationships in the data, such as clustering tendencies or separations between different sentiment values.\nThe only trend that appears in sentiment is that lower sentiments appear lower across principal component 2 and increase with it. This could mean a couple of things:\n\nThe lack of distinct clusters might indicate that the variables in the dataset do not exhibit strong groupings or separations related to the target variable\nPCA is a linear dimensionality reduction method, meaning it captures only linear relationships in the data. If the relationships between variables and sentiment are non-linear, PCA might not reveal meaningful clusters.\nIf the explained variance ratio of the first two components is relatively low, it suggests that the 2D representation does not capture much of the total variance in the data.\n\nIn our case the 3rd explanation makes the most sense as we saw in the previous graph how the variance is not explained very well until about 6 or 7 components. Let’s check out the rank varibles.\n\n# Reduce dimensions to 2D\npca_2d = PCA(n_components=2)\n# fit PCA to scaled data\npca_2d_result = pca_2d.fit_transform(scaled_df)\n\n# plot resulting 2 d representation of data \nplt.scatter(pca_2d_result[:, 0], pca_2d_result[:, 1], c=df['sentiment'], cmap='viridis')\n# label the plot\nplt.title('PCA: 2D Visualization')\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\nplt.colorbar(label='Sentiment Score')\nplt.show()\n\n\n\n\n\n\n\n\nBelow we graph the principal components for all the variables that were ranked for the bike routes. We begin to see some clusters or trends in these plots.\n\n# define rank vars\nrank_vars = ['terrain','traffic', 'scenery']\n# make subplots to plot them next to eachother\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\n# loop through the axes and plot each\nfor i in range(len(axes)):\n    im = axes[i].scatter(pca_2d_result[:, 0], pca_2d_result[:, 1], c=df[rank_vars[i]], cmap='viridis')\n    # add colorbar to each as they are all different\n    fig.colorbar(im, label=f'{rank_vars[i].capitalize()} Score', ax=axes[i])\n# label the plots\nfig.suptitle('PCA: 2D Visualization')\nfig.supxlabel('Principal Component 1')\nfig.supylabel('Principal Component 2')    \nplt.show()\n\n\n\n\n\n\n\n\n\n\nTSNE\nThis code applies t-Distributed Stochastic Neighbor Embedding (t-SNE), a non-linear dimensionality reduction technique, to visualize the dataset in two dimensions. Unlike PCA, which is linear, t-SNE is designed to preserve local structure in the data, making it particularly effective for revealing patterns such as clusters in datasets with complex relationships.\nSince we have a relatively small dataset (only 43 observations), we will search across a smaller range of perplexity values since the value controls how many neighbors are used for each point. Here we iterate over the perplexity values of 5 to 30, computing the KL Divergence at each perplexity, and plot them against each other. Perplexities that yield lower KL divergence indicate that the t-SNE embedding is better at maintaining the data’s structure. This helps determine an appropriate perplexity value for the dataset without relying solely on trial-and-error. We don’t see any substantial improvements after 20, and adding more might distort as we near the total number of observations.\n\n# initialize list to hold kl div vals and which perplexities we want to test\nkl_vals = []\nperps = range(5,30)\n# iterate over the perplexities\nfor i in perps:\n    # fit tsne with using current perplexity\n    tsne = TSNE(perplexity=i, random_state=24).fit(scaled_df)\n    # append kl divergence\n    kl_vals.append(tsne.kl_divergence_)\n# plot kl divergence against perplexity\nplt.plot(perps, kl_vals, marker='o')\nplt.title('KL Divergence by TSNE Perplexity')\nplt.xlabel('Perplexity')\nplt.ylabel('KL Divergence')\nplt.show()\n\n\n\n\n\n\n\n\nThe process begins by initializing t-SNE with two dimensions (n_components=2) to reduce the data into a 2D space suitable for visualization. The perplexity parameter, set to 20, controls the balance between local and global structure in the embedding, while a fixed random_state ensures reproducibility of the results. The algorithm transforms the scaled features into a new coordinate system, capturing the intricate non-linear relationships that may not be evident in PCA’s linear projections. The 2D results are plotted as a scatter plot, where each point corresponds to a data instance. The points are color-coded by the sentiment column to visually explore whether distinct groupings or gradients align with the sentiment values. We don’t see any distinctive clustering in the data across the sentiment score.\n\n# Apply t-SNE\ntsne = TSNE(n_components=2, perplexity=20, random_state=24)\ntsne_result = tsne.fit_transform(scaled_df)\n# Visualize t-SNE results\nplt.scatter(tsne_result[:, 0], tsne_result[:, 1], c=df['sentiment'], cmap='viridis', alpha=0.8)\nplt.title('t-SNE: 2D Visualization')\nplt.xlabel('t-SNE Dimension 1')\nplt.ylabel('t-SNE Dimension 2')\nplt.colorbar(label='Sentiment Score')\nplt.show()\n\n\n\n\n\n\n\n\nSimilar to above with PCA. We plot the t-SNE again using the ranked variables to color the points. There still doesn’t seem to be any obvious clustering, but there is some patterns seen.\n\n# make subplots to plot them next to eachother\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\n# loop through the axes and plot each\nfor i in range(len(axes)):\n    im = axes[i].scatter(tsne_result[:, 0], tsne_result[:, 1], c=df[rank_vars[i]], cmap='viridis')\n    # add colorbar to each as they are all different\n    fig.colorbar(im, label=f'{rank_vars[i].capitalize()} Score', ax=axes[i])\n# label the plots\nfig.suptitle('t-SNE: 2D Visualization')\nfig.supxlabel('t-SNE Dimension 1')\nfig.supylabel('t-SNE Dimension 2')    \nplt.show()\n\n\n\n\n\n\n\n\n\n\nEvaluation\nBoth PCA and t-SNE were applied to reduce the dataset’s dimensionality for visualization, but neither method produced distinct, well-separated clusters. However, some patterns were observed, suggesting that the data does contain structure, although not strong enough for clear cluster separation in a 2D representation. This outcome highlights the need to carefully evaluate the strengths and limitations of each method when applied to high-dimensional data.\nAs a linear technique, PCA captures the directions of maximum variance in the data and projects it onto fewer dimensions. It excels at preserving global structure, making it effective for understanding overarching patterns or trends. However, it’s reliance on linear projections means it may not reveal subtle, non-linear relationships. The cumulative explained variance plot provided insight into how much of the data’s variability is retained by the reduced components.\nIn contrast, t-SNE is designed to handle non-linear structures by preserving local similarities between data points. Its visualization often reveals small-scale patterns, such as clusters of similar instances, that might be missed by PCA. In this case, t-SNE revealed patterns that were not fully captured by PCA, but the lack of strong, distinct groupings suggests that either the data does not have well-defined clusters.\nThe following are some scenearios in which one method might be better than the other: - PCA is ideal when the primary goal is dimensionality reduction for interpretability, feature analysis, or global trend visualization. It is computationally efficient and works well with linearly separable data. - t-SNE is better suited for uncovering non-linear patterns and exploring local relationships, especially when clustering or separation is of interest in highly complex datasets. However, it is less effective for preserving global data structure and requires careful parameter tuning."
  },
  {
    "objectID": "technical-details/unsupervised-learning/main.html#part-2-clustering-methods",
    "href": "technical-details/unsupervised-learning/main.html#part-2-clustering-methods",
    "title": "Unsupervised Learning",
    "section": "Part 2: Clustering Methods",
    "text": "Part 2: Clustering Methods\nNext we will apply clustering techniques to the data to uncover any groupings that exist.\n\nK-Means\nK-Means is a widely-used clustering algorithm that partitions a dataset into a pre-defined number of clusters. It operates by initializing cluster centroids, assigning each data point to the nearest centroid, and iteratively updating the centroids based on the mean positions of points within each cluster. This process continues until the assignments stabilize, minimizing the within-cluster variance.\nA key aspect of K-Means is determining the optimal number of clusters, often guided by methods such as the Elbow Method or Silhouette Score Analysis. The Elbow Method involves plotting the inertia, or the sum of squared distances of samples to their cluster, against the number of clusters and looking for a point where adding more clusters yields diminishing improvements. Silhouette score evaluates cluster quality by measuring how similar a point is to its own cluster compared to others. It compares the average distance between a data point and other points in its cluster to the average distance to points in other clusters. While K-Means is computationally efficient and effective for well-separated clusters, it assumes spherical cluster shapes and may perform poorly with non-spherical distributions or data with significant outliers.\nBelow, we perform both methods to select an optimal number of clusters. First, we loop over the different values for the number of clusters and store their inertia and silhouette scores. We then plot these against the number of clusters to find a point that is diminishing returns for the elbow method, or the best score for silhouette score. We see somewhat of a drop-off at 8 or 9 for the elbow silhouette score so we cross check with the elbow method. While the inertia continues to decrease, it displays diminishing returns at this point.\n\n# initialize the k vals to test, and lists to store scores\nk_vals = range(2,20)\nsil_scores = []\ninertias = []\n# iterate over k vals\nfor k in k_vals:\n    # fit the model to our data using current k\n    kmeans_model = KMeans(n_clusters=k, random_state=24).fit(scaled_df)\n    # append inertia to list\n    inertias.append(kmeans_model.inertia_)\n    # Extract score and append to list. Appene current k\n    score = silhouette_score(scaled_df, kmeans_model.labels_)\n    sil_scores.append(score)\n\n# plot elbow method\nplt.figure()\nplt.plot(k_vals, inertias, \"-o\")\nplt.title(\"Optimal clusters using Elbow Method\")\nplt.ylabel(\"Intertias\")\nplt.xlabel(\"Num Clusters\")\nplt.show()\n# plot silouette score \nplt.figure()\nplt.plot(k_vals, sil_scores, '-o')\nplt.title(\"Optimal clusters using Silhouete Score\")\nplt.ylabel(\"Silhouette Score\")\nplt.xlabel(\"Num Clusters\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHere, the K-Means algorithm is applied with 8 clusters and each data point is assigned to one of these clusters, the resulting labels added to the DataFrame under the column kmeans_cluster. For visualization, the code uses the t-SNE result to map the high-dimensional data into two dimensions, where points are plotted and color-coded by their assigned K-Means cluster. The scatter plot illustrates how the clusters identified by K-Means are distributed in the 2 dimensional space.\nThe graph reveals reasonably well-defined clusters, indicating that the K-Means algorithm has effectively grouped similar data points. However, the clusters are unbalanced, with some containing very few points while others are relatively large. This imbalance could be explained by inherent characteristics of the dataset, such as a naturally skewed distribution of data or an uneven density of points across the feature space. The imbalance in cluster sizes highlights a potential limitation of K-Means in this context. While the algorithm minimizes variance within clusters, it assumes clusters of similar sizes and may assign small groups to their own clusters if their variance significantly differs from larger groups.\n\n# Optimal Clusters\noptimal_kmeans = KMeans(n_clusters=8, random_state=24)\ndf['kmeans_cluster'] = optimal_kmeans.fit_predict(scaled_df)\n\n# plot points in tsne space, colored on kmeans cluster\nplt.scatter(tsne_result[:, 0], tsne_result[:, 1], c=df['kmeans_cluster'])\nplt.title('t-SNE Clusters with K-Means')\nplt.xlabel('t-SNE Dimension 1')\nplt.ylabel('t-SNE Dimension 2')\nplt.colorbar()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nDBSCAN\nDBSCAN, which stands for Density-Based Spatial Clustering of Applications with Noise, is a non-parametric clustering algorithm that identifies clusters based on data density. It groups points that are densely packed together while marking points in low-density regions as noise. The most important hyper-parameters for DBSCAN are eps (maximum distance for points to be considered neighbors) and min_samples (minimum number of points required to form a dense region).\nUnlike K-Means, DBSCAN does not require specifying the number of clusters in advance, making it particularly useful for datasets with irregular cluster shapes or varying densities. However, parameter selection is crucial. Techniques like examining the k-distance plot can help identify an appropriate eps value by finding a knee point, where the distance increases sharply. DBSCAN is robust to noise and handles non-spherical clusters well, but it may struggle with high-dimensional data where density estimation becomes challenging or when eps is not appropriately tuned for the dataset’s scale.\nThe code below steps through identifying the optimal parameters for DBSCAN. This 2D grid search covers ranges for both eps and min_sample calculates the silhouette score at every combination of the two parameters, updating the best score and parameter values if better than what has been seen before. Since we are dealing with data that is fairly spread out in the vector space, we look at higher values of eps than is traditionally used. Also, note that in order to calculate silhouette score, the number of clusters needs to be at least 2 and less than the number of observations in the data. After iterating through all possible combinations, the code prints the best silhouette score, along with the corresponding eps and min_samples values.\nThis approach serves to automate the parameter tuning process for DBSCAN, which can be challenging since the algorithm’s performance is highly sensitive to eps and min_samples. By evaluating all combinations within the specified ranges and using the silhouette score as a measure of quality, this method ensures that the best-performing parameters are selected.\n\n# intialize values\nbest_eps = None\nbest_min_sample = None\nbest_score = -1\n# iterate through values for both eps values and min_sample\nfor eps in np.arange(.1,4,.1):\n    for min_sample in range(1,10):\n        # make dbscan model with current parameters\n        dbscan_model = DBSCAN(eps=eps, min_samples=min_sample).fit(scaled_df)\n        # if labels fit within requirements, calculate silhouette score\n        if 1 &lt; len(set(dbscan_model.labels_)) &lt; len(scaled_df):\n            score = silhouette_score(scaled_df, dbscan_model.labels_)\n            # if current score is better than our best, reset parameters\n            if score &gt; best_score:\n                best_score = score\n                best_eps, best_min_sample = eps, min_sample\n\n# Ouput results\nprint(\"Best Score:\", best_score, \"\\nBest Epsilon:\", best_eps, \"\\nBest min sample: \", best_min_sample)\n\nBest Score: 0.3176437786872938 \nBest Epsilon: 3.4000000000000004 \nBest min sample:  3\n\n\nHere the DBSCAN algorithm is applied with the optimal parameters to our dataset and the predicted clusters are added to the data frame. Next, the scatter plot maps the cluster assignments onto the 2D t-SNE space of the data. Each point is color-coded according to its dbscan_cluster label, with a color bar to distinguish different clusters.\nSeveral points are labeled as -1, representing noise. This indicates that these points were in low-density areas or isolated regions of the dataset, which DBSCAN appropriately excludes from clusters. While this can reflect meaningful patterns, such as outliers or transitional areas between clusters, it may also suggest that some relevant data points are being excluded as in our case of attempting to cluster bike routes. We also notice that the clusters uneven in size, with one containing all but three of the data points. This imbalance often occurs with DBSCAN, as the algorithm naturally groups points into clusters based on density rather than trying to create clusters of equal size. Overall, the clusters aren’t very informative, highlighting the challenges of interpreting imbalanced clusters and noise in the context of the dataset.\n\n# fit dbscan with optimal params and add column to df\ndbscan = DBSCAN(eps=best_eps, min_samples=best_min_sample)\ndf['dbscan_cluster'] = dbscan.fit_predict(scaled_df)\n# plot the clusters\nplt.scatter(tsne_result[:, 0], tsne_result[:, 1], c=df['dbscan_cluster'], label=df['dbscan_cluster'])\nplt.title('t-SNE Clusters with DBSCAN')\nplt.xlabel('t-SNE Dimension 1')\nplt.ylabel('t-SNE Dimension 2')\nplt.colorbar()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nHierarchical Clustering\nHierarchical clustering builds a tree-like structure to represent the relationships between data points. It comes in two forms: agglomerative (bottom-up) and divisive (top-down). Agglomerative clustering, the more common approach, starts with each data point as its own cluster and merges the closest clusters iteratively until a single cluster is formed. This is the approach we will use in our analysis.\nThere are several important hyper-parameters with agglomerative clustering, such as, choice of linkage criteria, choice of distance metric, and number of clusters. However, in our analysis we will just focus on n_clusters as the other two are more complex and reach beyond the scope of our analysis. Hierarchical clustering is effective for small to medium-sized datasets where relationships between points are more intuitive. However, it can be computationally expensive for large datasets and may suffer from sensitivity to noise and outliers.\nThis code below is designed to evaluate the performance of the Agglomerative Clustering algorithm across a range of potential cluster counts using the Silhouette Score. The goal is to identify the optimal number of clusters by analyzing how well-separated the clusters are in terms of their cohesion (internal) and separation (external). We iterate over a range of clusters, knowing we need at least 2 and picking a value lower than our total observations. For each number of clusters, we create an instance of the AgglomerativeClustering model with the current number of clusters, fit the model to the scaled dataset, and calculate the silhouette score. Then plot these scores against the number of clusters. We see a stark drop after 3 clusters and then a slow build to a local maximum at 18. While 3 clusters produces a better result, the behavior around the point is less predictable.\n\n# initialize to hold info\nn_vals  = range(2,30)\nsil_scores = []\n# loop through n values, need at least 2 clusters for silhouette\nfor n in n_vals:\n    # fit the model to our data using current n\n    cluster_model = AgglomerativeClustering(n_clusters=n).fit(scaled_df)\n    # get score and add to list\n    score = silhouette_score(scaled_df, cluster_model.labels_)\n    sil_scores.append(score)\n    \n# plot the scores against clusts\nplt.plot(n_vals, sil_scores, '-o')\nplt.title(\"Optimal clusters using Silhouete Score\")\nplt.ylabel(\"Silhouette Score\")\nplt.xlabel(\"Num Clusters\")\nplt.show()\n\n\n\n\n\n\n\n\nAs explained above, the behavior near 3 clusters is less predictable, so here we apply the clustering using the other maximum of 18 clusters. Similar as what was done with K-Means and DBSCAN, we plot the data in the 2D t-SNE space color based on the predicted cluster assignments.\nThe clusters appear reasonably well-separated, with distinct groups of points that reflect the underlying structure of the data. This suggests that Agglomerative Clustering has identified meaningful patterns or groupings within the dataset. However, the presence of a relatively large number of clusters, could indicate that the clustering algorithm has over-partitioned the data. The high number of clusters could also be indicative of the algorithm’s sensitivity to the distance metric and the scale of the data. As seen in the second plot, where we try 3 clusters, the outcome is even less informative.\n\n# fit model using 2 clusters\nagg_cluster = AgglomerativeClustering(n_clusters=18)\n# add predictions back to df\ndf['agg_cluster'] = agg_cluster.fit_predict(scaled_df)\n\n# plot points colored on agglomerative cluster\nplt.scatter(tsne_result[:, 0], tsne_result[:, 1], c=df['agg_cluster'])\nplt.title('t-SNE Clusters with Hierarchical Clustering')\nplt.xlabel('t-SNE Dimension 1')\nplt.ylabel('t-SNE Dimension 2')\nplt.colorbar()\nplt.show()\n\n# plot again using only 2 clusters\ncluster3 = AgglomerativeClustering(n_clusters=3).fit_predict(scaled_df)\nplt.scatter(tsne_result[:, 0], tsne_result[:, 1], c=cluster3)\nplt.title('t-SNE Clusters with Hierarchical Clustering')\nplt.xlabel('t-SNE Dimension 1')\nplt.ylabel('t-SNE Dimension 2')\nplt.colorbar()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResults\nIn this analysis, three clustering algorithms—K-Means, DBSCAN, and Agglomerative Clustering—were applied to the dataset of bike routes in Washington, DC, with the goal of identifying natural groupings of the routes based on their features, such as distance, ratings, descriptions, and sentiment\nK-Means clustering provided a reasonable grouping of bike routes into 10 clusters, as determined by evaluating different cluster counts and selecting the optimal number based on silhouette scores. The resulting clusters appeared somewhat balanced in terms of size, though there were a few smaller clusters containing fewer routes. The clusters formed by K-Means generally aligned with routes that shared common features, such as similar distances or ratings.\nDBSCAN was effective at identifying clusters of varying shapes and sizes. The algorithm’s ability to classify some data points as noise (assigned the label -1) highlighted routes that did not fit well into any of the primary clusters. While DBSCAN’s ability to identify noise is beneficial for excluding irrelevant data, it resulted in an uneven distribution of clusters. Many of the clusters formed were relatively small, and several routes were classified as noise. This imbalance points to the algorithm’s sensitivity to the density of points, and it suggests that DBSCAN may be more suited for datasets that aren’t as empty in the vector space as ours.\nAgglomerative Clustering with 17 clusters produced the most granular results, splitting the bike routes into small and imbalanced clusters. This high number of clusters indicated that the algorithm over-partitioned the data, potentially identifying small, subtle groupings that might not have significant practical meaning. The large number of clusters posed a challenge for interpreting the results, as the small clusters could represent noise or slight variations in the routes, which may not be as valuable for decision-making."
  },
  {
    "objectID": "technical-details/eda/main.html",
    "href": "technical-details/eda/main.html",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "With our processed data, we created numerous visualizations to uncover the underlying patterns in the bike trail dataset. Most of the analyses focused on univariate relationships, though we also explored some bivariate relationships, particularly between trail ratings. Additionally, we examined the potential for clustering by comparing mileage with sentiment, using the trail’s scenery score as a color-coded feature."
  },
  {
    "objectID": "technical-details/eda/main.html#univariate-analysis",
    "href": "technical-details/eda/main.html#univariate-analysis",
    "title": "Exploratory Data Analysis",
    "section": "Univariate Analysis",
    "text": "Univariate Analysis\n\nNumerical Variables\nWe analyzed the distributions of numerical variables, particularly mileage and sentiment:\n\nMileage: A discrete variable, categorized into bins for easier analysis. The distribution shows that most trails fall within the 10-120 mile range, with a slight right skew indicating a few longer trails (up to 175 miles).\nSentiment: A continuous variable analyzed using Kernel Density Estimation. The distribution reveals that most sentiments are positive, concentrated within the 0-0.8 range. The bimodal nature of the distribution indicates peaks around 0 and 0.6.\n\n\n\nCategorical Variables\nBar charts helped us visualize the distributions of trail ratings—terrain, traffic, and scenery:\n\nTerrain: The only rating using the full range (1-5). Most trails are rated 3, with fewer trails rated 4 or 5.\nTraffic: Ranges from 1-4, with most trails rated 2 or 3.\nScenery: Restricted to scores of 1-3, with the majority of trails rated 1 or 2."
  },
  {
    "objectID": "technical-details/eda/main.html#bivariate-analysis",
    "href": "technical-details/eda/main.html#bivariate-analysis",
    "title": "Exploratory Data Analysis",
    "section": "Bivariate Analysis",
    "text": "Bivariate Analysis\n\nHeatmaps\nWe explored relationships between trail ratings using heatmaps:\n\nTerrain vs. Scenery: The combination of terrain (3) and scenery (1) is the most frequent.\nTerrain vs. Traffic: The most common combination is when both ratings are 3.\nTraffic vs. Scenery: Most common combinations are scenery (1) and traffic (2) as well as scenery (2) and traffic (3).\n\n\n\nCorrelation Analysis\nA correlation matrix comparing mileage, sentiment, and the three ratings showed no strong correlations. However, sentiment and terrain rating had the highest correlation, suggesting that challenging terrains might lead to more negative sentiments."
  },
  {
    "objectID": "technical-details/eda/main.html#multivariate-analysis",
    "href": "technical-details/eda/main.html#multivariate-analysis",
    "title": "Exploratory Data Analysis",
    "section": "Multivariate Analysis",
    "text": "Multivariate Analysis\nTo identify potential clusters, we visualized distance vs. sentiment, color-coded by the scenery score and annotated with the loop variable (loop vs. non-loop trails). The scatter plot revealed:\n\nNo clear clusters based on distance and sentiment.\nScenery scores often grouped closely, with no discernible differences between loop and non-loop trails."
  },
  {
    "objectID": "technical-details/eda/main.html#statistical-tests",
    "href": "technical-details/eda/main.html#statistical-tests",
    "title": "Exploratory Data Analysis",
    "section": "Statistical Tests",
    "text": "Statistical Tests\nWe conducted a series of statistical tests to analyze the relationships between numerical, binary, and categorical features in our dataset. Below, we outline the methodology and results for each type of test:\n\nKolmogorov-Smirnov Test\nTo assess the normality of the numerical variables (mileage and sentiment), we used the Kolmogorov-Smirnov test. The results indicated that both variables appear to be normally distributed:\n\nSentiment: p-value ≈ 0.198\nMileage: p-value ≈ 0.091\n\nSince the p-values are greater than 0.05, we fail to reject the null hypothesis, concluding that both variables are likely normally distributed.\n\n\nt-Tests (Continuous vs. Binary Variables)\nWe performed t-tests to compare the means of numerical variables (sentiment and mileage) across each binary variable in the dataset. For every combination:\n\nThe p-values were greater than 0.05.\nThis indicates that we fail to reject the null hypothesis, suggesting no significant differences in means between the numerical variables from the lens of the the binary features.\n\n\n\nChi-Squared Tests (Categorical Features)\nWe used chi-squared tests to examine the independence between all pairs of categorical variables (traffic, terrain, scenery, state1, and state2). The results revealed statistically significant associations for the following pairs:\n\nTraffic vs. Terrain: p-value ≈ 0.039\nTerrain vs. State1: p-value ≈ 0.033\nState1 vs. State2: p-value ≈ 5.61e-11\n\nFor these pairs, we reject the null hypothesis at a significance level of 0.05, concluding that these categorical variables are not independent. All other pairs yielded p-values greater than 0.05, indicating no evidence of dependence.\n\n\nANOVA Tests (Continuous vs. Categorical Variables)\nWe conducted ANOVA tests to compare the means of continuous variables (sentiment and mileage) across the levels of categorical variables. Notable results include:\n\nSentiment across Terrain Levels: p-value ≈ 0.028\n\nThis suggests a significant difference in sentiment means across terrain categories, leading us to reject the null hypothesis.\n\nSentiment across Traffic Levels: p-value ≈ 0.059\n\nAlthough this result is close, it does not meet the 0.05 significance threshold.\n\n\nFor all other tests, the p-values were greater than 0.05, indicating no significant differences in means across the levels of the binary or categorical variables.\n\n\nStatistical Summary\n\nNormality (Kolmogorov-Smirnov): Both sentiment and mileage are likely normally distributed.\nt-Tests: No significant differences in means between numerical and binary variables.\nChi-Squared Tests: Significant associations observed for traffic vs. terrain, terrain vs. state1, and state1 vs. state2.\nANOVA: Significant differences in sentiment across terrain levels; no other significant results.\n\nThese findings provide insights into the relationships within the dataset and guide further analysis."
  },
  {
    "objectID": "technical-details/eda/main.html#key-insights",
    "href": "technical-details/eda/main.html#key-insights",
    "title": "Exploratory Data Analysis",
    "section": "Key Insights",
    "text": "Key Insights\n\nSentiment is generally positive, with a bimodal distribution.\nMost trails are relatively short (10-120 miles), though a few exceed 175 miles.\nTerrain ratings are diverse, but traffic and scenery ratings have narrower ranges.\nNo strong correlations exist between numerical or categorical variables.\nDistinct clusters are not evident based on distance, sentiment, or scenery."
  },
  {
    "objectID": "technical-details/eda/main.html#conclusion-and-next-steps",
    "href": "technical-details/eda/main.html#conclusion-and-next-steps",
    "title": "Exploratory Data Analysis",
    "section": "Conclusion and Next Steps",
    "text": "Conclusion and Next Steps\nThe EDA revealed limited patterns for effectively grouping trails. While the correlation matrix and scatter plots showed minimal relationships, the insights into distributions and rating combinations inform our understanding of the data. These findings will guide the next steps:\n\nModeling: Explore whether machine learning can identify subtle patterns.\nFeature Engineering: Consider different variable relationships or transformations to improve clustering potential.\n\nAll visualizations, including heatmaps, bar charts, and scatter plots, as well as statistical testing outputs, can be found in the Code section below."
  },
  {
    "objectID": "technical-details/data-cleaning/main.html",
    "href": "technical-details/data-cleaning/main.html",
    "title": "Data Cleaning",
    "section": "",
    "text": "Cleaning the raw trail data was a critical step in extracting meaningful insights. The descriptions of each bike trail contained a wealth of information, making data cleaning essential for conducting deeper exploratory analysis and enabling robust machine learning applications. It’s important to note that data cleaning is a dynamic and iterative process. As this project evolves, additional cleaning may be required. Below is a summary of the transformations applied to produce the cleaned dataset.\n\n\n\n\nUnpaved: Binary variable (1 = unpaved road, 0 = paved road).\nFlat: Binary variable (1 = flat road, 0 = not flat).\nWorkout: Binary variable (1 = trail designed for workouts, 0 = not designed for workouts).\nPark: Binary variable (1 = trail located in a park, 0 = not located in a park).\nRiver: Binary variable (1 = trail runs along a river, 0 = does not run along a river).\nLoop: Binary variable (1 = trail forms a loop, 0 = does not form a loop).\nSentiment: Float variable measuring the sentiment score of the trail description.\nState1: The state where the trail begins.\nState2: The state where the trail ends.\n\n\n\n\nThis dataset initially had no missing values—every cell contained data. To confirm, we used the is.na().sum() function in Python to verify the absence of null or missing values. When text-scraping trail descriptions to generate binary variables (e.g., identifying if the word “workout” was present), missing words were assumed to indicate the absence of that characteristic, and the corresponding cell was assigned a value of 0.\n\n\n\nOutliers were not a significant concern. For instance, while the C&O Towpath trail spans 184 miles—considerably longer than most other trails—removing such outliers was unnecessary. Given the limited number of bike trails in the DMV area, retaining all observations was crucial for maintaining data integrity and size.\n\n\n\nThe raw dataset contained two data types: object (trail names and descriptions) and int64 (ratings and mileage). After cleaning, the dataset included object, int64, and float64 types:\n\nObject: name, state1, state2.\nFloat64: sentiment.\nInt64: All other features.\n\nDescriptions were transformed to lowercase for consistency and ease of keyword matching. The most significant transformation involved converting descriptions into multiple binary (one-hot-encoded) features based on meaningful keywords, as described in the “New Variables” section. State information was also extracted using lists of specific locations within Virginia, Maryland, DC, and Pennsylvania, allowing us to assign values to state1 and state2. This process enabled the extraction of numerical data from text, enriching the dataset for subsequent machine learning analyses.\n\n\n\nGiven the significant right skew in the mileage distribution, normalization was applied. We used z-score normalization to scale this variable, ensuring it would not disproportionately influence machine learning models. Both normalized and unnormalized mileage distributions are provided in the ‘Code’ section below.\n\n\n\nSubsetting is unnecessary due to the already small size of the dataset."
  },
  {
    "objectID": "technical-details/data-cleaning/main.html#overview",
    "href": "technical-details/data-cleaning/main.html#overview",
    "title": "Data Cleaning",
    "section": "",
    "text": "Cleaning the raw trail data was a critical step in extracting meaningful insights. The descriptions of each bike trail contained a wealth of information, making data cleaning essential for conducting deeper exploratory analysis and enabling robust machine learning applications. It’s important to note that data cleaning is a dynamic and iterative process. As this project evolves, additional cleaning may be required. Below is a summary of the transformations applied to produce the cleaned dataset."
  },
  {
    "objectID": "technical-details/data-cleaning/main.html#explanation-of-new-variables",
    "href": "technical-details/data-cleaning/main.html#explanation-of-new-variables",
    "title": "Data Cleaning",
    "section": "",
    "text": "Unpaved: Binary variable (1 = unpaved road, 0 = paved road).\nFlat: Binary variable (1 = flat road, 0 = not flat).\nWorkout: Binary variable (1 = trail designed for workouts, 0 = not designed for workouts).\nPark: Binary variable (1 = trail located in a park, 0 = not located in a park).\nRiver: Binary variable (1 = trail runs along a river, 0 = does not run along a river).\nLoop: Binary variable (1 = trail forms a loop, 0 = does not form a loop).\nSentiment: Float variable measuring the sentiment score of the trail description.\nState1: The state where the trail begins.\nState2: The state where the trail ends."
  },
  {
    "objectID": "technical-details/data-cleaning/main.html#managing-missing-data",
    "href": "technical-details/data-cleaning/main.html#managing-missing-data",
    "title": "Data Cleaning",
    "section": "",
    "text": "This dataset initially had no missing values—every cell contained data. To confirm, we used the is.na().sum() function in Python to verify the absence of null or missing values. When text-scraping trail descriptions to generate binary variables (e.g., identifying if the word “workout” was present), missing words were assumed to indicate the absence of that characteristic, and the corresponding cell was assigned a value of 0."
  },
  {
    "objectID": "technical-details/data-cleaning/main.html#outlier-detection-and-treatment",
    "href": "technical-details/data-cleaning/main.html#outlier-detection-and-treatment",
    "title": "Data Cleaning",
    "section": "",
    "text": "Outliers were not a significant concern. For instance, while the C&O Towpath trail spans 184 miles—considerably longer than most other trails—removing such outliers was unnecessary. Given the limited number of bike trails in the DMV area, retaining all observations was crucial for maintaining data integrity and size."
  },
  {
    "objectID": "technical-details/data-cleaning/main.html#data-type-corrections-and-formatting",
    "href": "technical-details/data-cleaning/main.html#data-type-corrections-and-formatting",
    "title": "Data Cleaning",
    "section": "",
    "text": "The raw dataset contained two data types: object (trail names and descriptions) and int64 (ratings and mileage). After cleaning, the dataset included object, int64, and float64 types:\n\nObject: name, state1, state2.\nFloat64: sentiment.\nInt64: All other features.\n\nDescriptions were transformed to lowercase for consistency and ease of keyword matching. The most significant transformation involved converting descriptions into multiple binary (one-hot-encoded) features based on meaningful keywords, as described in the “New Variables” section. State information was also extracted using lists of specific locations within Virginia, Maryland, DC, and Pennsylvania, allowing us to assign values to state1 and state2. This process enabled the extraction of numerical data from text, enriching the dataset for subsequent machine learning analyses."
  },
  {
    "objectID": "technical-details/data-cleaning/main.html#normalization-and-scaling",
    "href": "technical-details/data-cleaning/main.html#normalization-and-scaling",
    "title": "Data Cleaning",
    "section": "",
    "text": "Given the significant right skew in the mileage distribution, normalization was applied. We used z-score normalization to scale this variable, ensuring it would not disproportionately influence machine learning models. Both normalized and unnormalized mileage distributions are provided in the ‘Code’ section below."
  },
  {
    "objectID": "technical-details/data-cleaning/main.html#subsetting-data",
    "href": "technical-details/data-cleaning/main.html#subsetting-data",
    "title": "Data Cleaning",
    "section": "",
    "text": "Subsetting is unnecessary due to the already small size of the dataset."
  },
  {
    "objectID": "technical-details/data-collection/main.html",
    "href": "technical-details/data-collection/main.html",
    "title": "Data Collection",
    "section": "",
    "text": "The primary objective of this project is to leverage data from bikewashington.org to provide actionable insights about bike paths in Washington, DC. By analyzing and presenting detailed information about these trails, we aim to help riders make informed decisions about their routes. This knowledge will enhance their preparation and contribute to safer biking experiences across the city.\n\n\n\nOur motivation lies in supporting the biking community by empowering riders to choose trails that align with their specific needs and goals. Whether for exercise, commuting, or leisure, informed decisions about bike paths can optimize the overall experience. Additionally, providing better trail information is expected to inherently enhance safety, especially for those exploring new or unfamiliar routes.\n\n\n\n\nTrail Clustering: Group similar bike trails in Washington, DC, using algorithms such as KMeans Clustering and Spectral Clustering.\nLength Prediction: Develop a regression decision tree model to predict the length of a trail based on its other qualities.\nPersonalized Recommendations: Offer tailored trail recommendations for riders of varying experience levels, addressing their unique preferences.\n\n\n\n\nAll data used in this project originates from Bike Washington. The website provides a table of detailed information about bike routes within the DMV (DC, Maryland, and Virginia) area. Specifically, it includes:\n\nTrail Length: Measured in miles.\nTrail Name: The name of each bike route.\nTrail Description: A summary of the trail’s features.\nRatings: Scores for terrain difficulty, traffic levels, and scenic beauty.\n\n\n\n\nTerrain: A score of 1 corresponds to a very flat trail, while 5 represents extremely challenging climbs.\nTraffic: A score of 1 indicates minimal traffic, while 5 suggests heavy traffic conditions.\nScenery: A score of 1 indicates a highly scenic trail, whereas 5 represents less visually appealing routes.\n\n\n\n\n\nThe cleaned data was exported to a CSV file consisting of:\n\nRows: 43 (one for each trail).\nColumns: 6 (trail name, description, mileage, terrain rating, traffic rating, and scenery rating).\nData Types:\n\nstring for trail names and descriptions.\ninteger for mileage and ratings.\n\nRegression Target: mileage\nBinary Classification Target: insert here\nMulticlass-Classification Target: location of trail (Maryland, Virginia, or DC) - found in the description"
  },
  {
    "objectID": "technical-details/data-collection/main.html#goals",
    "href": "technical-details/data-collection/main.html#goals",
    "title": "Data Collection",
    "section": "",
    "text": "The primary objective of this project is to leverage data from bikewashington.org to provide actionable insights about bike paths in Washington, DC. By analyzing and presenting detailed information about these trails, we aim to help riders make informed decisions about their routes. This knowledge will enhance their preparation and contribute to safer biking experiences across the city."
  },
  {
    "objectID": "technical-details/data-collection/main.html#motivation",
    "href": "technical-details/data-collection/main.html#motivation",
    "title": "Data Collection",
    "section": "",
    "text": "Our motivation lies in supporting the biking community by empowering riders to choose trails that align with their specific needs and goals. Whether for exercise, commuting, or leisure, informed decisions about bike paths can optimize the overall experience. Additionally, providing better trail information is expected to inherently enhance safety, especially for those exploring new or unfamiliar routes."
  },
  {
    "objectID": "technical-details/data-collection/main.html#objectives",
    "href": "technical-details/data-collection/main.html#objectives",
    "title": "Data Collection",
    "section": "",
    "text": "Trail Clustering: Group similar bike trails in Washington, DC, using algorithms such as KMeans Clustering and Spectral Clustering.\nLength Prediction: Develop a regression decision tree model to predict the length of a trail based on its other qualities.\nPersonalized Recommendations: Offer tailored trail recommendations for riders of varying experience levels, addressing their unique preferences."
  },
  {
    "objectID": "technical-details/data-collection/main.html#data-source-information",
    "href": "technical-details/data-collection/main.html#data-source-information",
    "title": "Data Collection",
    "section": "",
    "text": "All data used in this project originates from Bike Washington. The website provides a table of detailed information about bike routes within the DMV (DC, Maryland, and Virginia) area. Specifically, it includes:\n\nTrail Length: Measured in miles.\nTrail Name: The name of each bike route.\nTrail Description: A summary of the trail’s features.\nRatings: Scores for terrain difficulty, traffic levels, and scenic beauty.\n\n\n\n\nTerrain: A score of 1 corresponds to a very flat trail, while 5 represents extremely challenging climbs.\nTraffic: A score of 1 indicates minimal traffic, while 5 suggests heavy traffic conditions.\nScenery: A score of 1 indicates a highly scenic trail, whereas 5 represents less visually appealing routes."
  },
  {
    "objectID": "technical-details/data-collection/main.html#data-structure-and-format",
    "href": "technical-details/data-collection/main.html#data-structure-and-format",
    "title": "Data Collection",
    "section": "",
    "text": "The cleaned data was exported to a CSV file consisting of:\n\nRows: 43 (one for each trail).\nColumns: 6 (trail name, description, mileage, terrain rating, traffic rating, and scenery rating).\nData Types:\n\nstring for trail names and descriptions.\ninteger for mileage and ratings.\n\nRegression Target: mileage\nBinary Classification Target: insert here\nMulticlass-Classification Target: location of trail (Maryland, Virginia, or DC) - found in the description"
  },
  {
    "objectID": "technical-details/data-collection/main.html#challenges",
    "href": "technical-details/data-collection/main.html#challenges",
    "title": "Data Collection",
    "section": "Challenges",
    "text": "Challenges\nDuring the data cleaning process, several technical challenges were encountered. These included overly generalized HTML formatting that did not ID or name any components in the site. Addressing these issues required extremely specific custom regular expressions and manual inspection to ensure data accuracy. Another challenge was getting the webdriver to work on a WSL connected device. There were several issues with getting Selenium to properly initialize communication with Google Chrome and the installed driver."
  },
  {
    "objectID": "technical-details/data-collection/main.html#conclusion-and-future-steps",
    "href": "technical-details/data-collection/main.html#conclusion-and-future-steps",
    "title": "Data Collection",
    "section": "Conclusion and Future Steps",
    "text": "Conclusion and Future Steps\nThe data cleaning process has provided a strong foundation for the analytical components of this project. Key technical accomplishments include the successful extraction, transformation, and storing of the data. The next step for us is to clean the data and add relevant features as needed for analysis down the road.\nFuture work will focus on:\n\nExpanding the Dataset: Incorporating additional data sources to improve trail coverage and diversity.\nFeature Engineering: Developing more advanced features, such as weather conditions, trail popularity, or proximity to public transit, to enhance model performance.\nUser Feedback Integration: Leveraging feedback from local riders to validate and refine trail ratings and recommendations.\nScaling Solutions: Automating the data cleaning pipeline for integration with larger datasets or real-time updates.\n\nBy continuing to refine and augment the dataset, this project aims to deliver actionable insights and tailored recommendations to the biking community."
  },
  {
    "objectID": "technical-details/supervised-learning/main.html",
    "href": "technical-details/supervised-learning/main.html",
    "title": "Supervised Learning",
    "section": "",
    "text": "In this analysis, we explore the performance of regression and classification decision tree models to understand the intricate relationships within our dataset. We found that the regression tree outperformed the linear regression model, likely because decision trees do not assume any specific functional form or distribution, whereas linear regression attempts to fit a straight line through the data, which may not be suitable for complex relationships. Decision trees, by learning simple decision rules from features, are better equipped to capture the underlying patterns in the bike path dataset.\n\n\n\n\n\nWe applied z-score normalization to the mileage feature to scale it appropriately with other features.\n\n\n\n\n\nGiven the limited size of the dataset, all available features were kept, with no extraction performed.\n\n\n\n\n\nCategorical features were one-hot encoded to convert them into a binary format suitable for modeling.\n\n\n\n\n\n\n\n\nWe used the train_test_split function from sklearn to divide the dataset into training and testing sets, applying a standard 80/20 split.\n\n\n\n\n\nThe dataset was divided such that 80% was used for training, and 20% was reserved for testing."
  },
  {
    "objectID": "technical-details/supervised-learning/main.html#data-preprocessing",
    "href": "technical-details/supervised-learning/main.html#data-preprocessing",
    "title": "Supervised Learning",
    "section": "",
    "text": "We applied z-score normalization to the mileage feature to scale it appropriately with other features.\n\n\n\n\n\nGiven the limited size of the dataset, all available features were kept, with no extraction performed.\n\n\n\n\n\nCategorical features were one-hot encoded to convert them into a binary format suitable for modeling."
  },
  {
    "objectID": "technical-details/supervised-learning/main.html#training-testing-strategy",
    "href": "technical-details/supervised-learning/main.html#training-testing-strategy",
    "title": "Supervised Learning",
    "section": "",
    "text": "We used the train_test_split function from sklearn to divide the dataset into training and testing sets, applying a standard 80/20 split.\n\n\n\n\n\nThe dataset was divided such that 80% was used for training, and 20% was reserved for testing."
  },
  {
    "objectID": "technical-details/supervised-learning/main.html#linear-regression",
    "href": "technical-details/supervised-learning/main.html#linear-regression",
    "title": "Supervised Learning",
    "section": "Linear Regression",
    "text": "Linear Regression\nWe began with linear regression as a baseline to understand how well a simple linear model could fit the data. Linear regression assumes a linear relationship between the target (‘sentiment’) and the input features. We evaluated the model using two metrics:\n\nRMSE (Root Mean Squared Error): Measures the error between predicted and actual values, with a lower value being desirable.\nR²: Represents the proportion of variance explained by the model, where higher values indicate better fits.\n\nFor this analysis, we obtained: - RMSE: 0.14 - R²: 0.03\nAlthough the RMSE is low, the R² value indicates a poor fit, suggesting that a linear model is insufficient for capturing the underlying relationships in the data. We decided to proceed with more complex models."
  },
  {
    "objectID": "technical-details/supervised-learning/main.html#regression-tree",
    "href": "technical-details/supervised-learning/main.html#regression-tree",
    "title": "Supervised Learning",
    "section": "Regression Tree",
    "text": "Regression Tree\nNext, we applied a regression tree, which is non-parametric and can dynamically fit the data by learning decision rules. We fine-tuned the model by testing various max_depth hyperparameters, which control the depth of the tree. We found that a max_depth of 2 minimized the testing error while avoiding overfitting.\n\nOptimal hyperparameter: max_depth = 2\nTraining RMSE: 0.11\nTesting RMSE: 0.048 (lower than the linear regression model)\n\nThe regression tree significantly outperformed linear regression in terms of RMSE, indicating that the model was better suited to capture the underlying patterns in the data."
  },
  {
    "objectID": "technical-details/supervised-learning/main.html#binary-classification-tree",
    "href": "technical-details/supervised-learning/main.html#binary-classification-tree",
    "title": "Supervised Learning",
    "section": "Binary Classification Tree",
    "text": "Binary Classification Tree\nAfter the regression task, we focused on a binary classification problem: predicting whether a bike path is a loop (1) or not (0). Given the poor R² from the linear regression, we chose to avoid logistic regression and instead used a decision tree for classification. We tuned the max_depth hyperparameter and found that a value of 7 yielded the best performance.\n\nOptimal hyperparameter: max_depth = 7\nAccuracy: 78%\nConfusion Matrix:\n\nNegative recall: 100%\nNegative precision: 75%\nPositive recall: 33%\nPositive precision: 100%\n\n\nThe model performed well in terms of accuracy, but the confusion matrix revealed that it frequently predicted the non-loop class (0), likely due to class imbalance in the dataset. This bias resulted in a low positive recall."
  },
  {
    "objectID": "technical-details/supervised-learning/main.html#multiclass-classification-tree",
    "href": "technical-details/supervised-learning/main.html#multiclass-classification-tree",
    "title": "Supervised Learning",
    "section": "Multiclass Classification Tree",
    "text": "Multiclass Classification Tree\nFinally, we aimed to predict the ‘state1’ variable, which represents multiple categories. We evaluated the model by testing various max_depth values to find the optimal setting. We selected max_depth = 2 based on its performance.\n\nOptimal hyperparameter: max_depth = 2\nTest Accuracy: 44%\n\nAlthough the model outperformed random guessing, with an accuracy of 44%, it was not highly predictive. The confusion matrix indicated that the model tended to predict the most prevalent class correctly, but struggled with the other categories."
  },
  {
    "objectID": "technical-details/supervised-learning/main.html#discussion",
    "href": "technical-details/supervised-learning/main.html#discussion",
    "title": "Supervised Learning",
    "section": "Discussion",
    "text": "Discussion\n\n1. Result Interpretation\n\nThe regression tree emerged as the best-performing model, with a testing RMSE of 0.048, which indicates a good fit. However, further testing with additional data would be important for validating its robustness.\nThe binary classification tree performed well overall, with 78% accuracy, but the confusion matrix highlighted issues with class imbalance. The model heavily favored predicting non-loop paths, which reduced its utility in predicting the loop class.\nThe multiclass classification model achieved an accuracy of 44%, which is marginally better than guessing randomly. It often predicted the most common class, but failed to predict the other categories accurately. More data and improved feature engineering would likely enhance the performance of this model.\n\n\n\n2. Model Performance Comparison\n\nAmong all models tested, the regression tree offered the best performance with the lowest RMSE. The binary classification tree showed promising accuracy but suffered from class imbalance issues. The multiclass model’s performance was the weakest, highlighting the need for better predictive features or more data.\n\n\n\n3. Insights Gained\n\nThe regression tree is the most reliable model for this dataset, as it can better capture non-linear relationships. For classification tasks, particularly binary classification, addressing class imbalance and tuning the model further is crucial. The multiclass model, while slightly better than random, would benefit from more data and better feature selection to improve predictive accuracy."
  },
  {
    "objectID": "technical-details/supervised-learning/main.html#linear-regression-1",
    "href": "technical-details/supervised-learning/main.html#linear-regression-1",
    "title": "Supervised Learning",
    "section": "Linear Regression",
    "text": "Linear Regression\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, plot_tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport random\n\n# Make a simple linear regression model to see what testing error arises\nrandom.seed(5000)\ndf = pd.read_csv('../../data/processed-data/dc_bike_routes.csv')\n\n# Split features and target\nY = df['sentiment']\nX = df.iloc[:, 2:12]\n\n# Split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=24)\n\n# Initialize Linear Regression model\nmodel = LinearRegression()\n\n# Train the model on the training data\nmodel.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred = model.predict(X_test)\n\n# Evaluate the model\ntest_error = mean_squared_error(y_test, y_pred) #Testing Error\nr2 = r2_score(y_test, y_pred)\n\n# Print performance metrics\nprint(\"Mean Squared Error:\", test_error)\nprint(\"R² Score:\", r2)\n\nMean Squared Error: 0.13784056412573972\nR² Score: 0.029290998492904396"
  },
  {
    "objectID": "technical-details/supervised-learning/main.html#regression-tree-1",
    "href": "technical-details/supervised-learning/main.html#regression-tree-1",
    "title": "Supervised Learning",
    "section": "Regression Tree",
    "text": "Regression Tree\n\n## Make a Regression Tree that predicts the sentiment of a bike path given mileage and other binary variables\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)\ny_train = y_train\ny_test = y_test\n\nhyper_parameters = []\ntrain_error = []\ntest_error = []\n\n# Optimize Hyperparameter\nfor value in range(1,20):\n\n    model = DecisionTreeRegressor(max_depth = value)\n\n    model.fit(x_train, y_train)\n\n    yp_train = model.predict(x_train)\n    yp_test = model.predict(x_test)\n\n    train_error_sample = mean_squared_error(y_train, yp_train)\n    test_error_sample = mean_squared_error(y_test, yp_test)\n\n    hyper_parameters.append(value)\n    train_error.append(train_error_sample)\n    test_error.append(test_error_sample)\n\n# Plot the data\nplt.plot(hyper_parameters, train_error, label=\"Training Error\", color=\"blue\", linestyle=\"-\", marker=\"o\")\nplt.plot(hyper_parameters, test_error, label=\"Testing Error\", color=\"red\", linestyle=\"--\", marker=\"x\")\n\n# Add labels and title\nplt.xlabel(\"Hyperparameter Range\")\nplt.ylabel(\"Mean Squared Error (Blue = Training & Red = Testing)\")\nplt.title(\"Line Plot of Training and Testing Error\")\n\n# Add a legend\nplt.legend()\n\n# Show the plot\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n# Make the best model and output the errors\nmodel_best = DecisionTreeRegressor(max_depth = 2)\n\nmodel_best.fit(x_train, y_train)\n\nyp_train = model_best.predict(x_train)\nyp_test = model_best.predict(x_test)\n\ntrain_error_best = mean_squared_error(y_train, yp_train)\ntest_error_best = mean_squared_error(y_test, yp_test)\n\nprint(\"Training Error:\", train_error_best)\nprint(\"Testing Error:\", test_error_best)\n\nTraining Error: 0.11066305675070026\nTesting Error: 0.047755677369614516"
  },
  {
    "objectID": "technical-details/supervised-learning/main.html#classification-trees",
    "href": "technical-details/supervised-learning/main.html#classification-trees",
    "title": "Supervised Learning",
    "section": "Classification Trees",
    "text": "Classification Trees\n\n# Functions for displaying accuracy and the model\n\n# Confusion Plot to visualize accuracy of the model later on\ndef confusion_plot(y_data, y_pred):\n    # Calculate and print accuracy\n    accuracy = accuracy_score(y_data, y_pred)\n    print(\"ACCURACY:\", accuracy)\n\n    if len(y_data.unique()) == 2:\n        neg_recall = recall_score(y_data == 0, (y_pred == 0))\n        neg_precision = precision_score((y_data) == 0, (y_pred == 0))\n        pos_recall = recall_score((y_data) == 1, (y_pred == 1))\n        pos_precision = precision_score((y_data) == 1, (y_pred == 1))\n\n        print(\"NEGATIVE RECALL (Y=0):\", neg_recall)\n        print(\"NEGATIVE PRECISION (Y=0):\", neg_precision)\n        print(\"POSITIVE RECALL (Y=1):\", pos_recall)\n        print(\"POSITIVE PRECISION (Y=1):\", pos_precision)\n\n    conf_matrix = confusion_matrix(y_data, y_pred)\n    print(conf_matrix)\n\n    disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\n    disp.plot()\n    plt.show()\n\n# Display a tree\ndef display_tree(model,X,Y):\n    fig = plt.figure(figsize=(25,20))\n    plot_tree(model,\n                feature_names=X.columns,\n                class_names=[str(c) for c in Y.unique()],\n                filled=True)\n\n    plt.show()\n\n\n# Try to predict loop based on other variables. FIrst, let's optimize the hyper parameters\nY_class_bin = df['loop']\nX_class_bin = pd.concat([df.iloc[:, 2:11], df['sentiment']], axis=1)\n\nx_train, x_test, y_train, y_test = train_test_split(X_class_bin, Y_class_bin, test_size = 0.2, random_state = 0)\n\ntest_results=[]\ntrain_results=[]\n\nfor num_layer in range(1,15):\n    model = DecisionTreeClassifier(max_depth=num_layer)\n    model = model.fit(x_train, y_train)\n\n    yp_train=model.predict(x_train)\n    yp_test=model.predict(x_test)\n\n    test_results.append([num_layer,accuracy_score(y_test, yp_test),recall_score(y_test, yp_test,pos_label=0),recall_score(y_test, yp_test,pos_label=1)])\n    train_results.append([num_layer,accuracy_score(y_train, yp_train),recall_score(y_train, yp_train,pos_label=0),recall_score(y_train, yp_train,pos_label=1)])\n\nfig, axes = plt.subplots(nrows=3, ncols=1, figsize=(10, 20))\n\naxes[0].plot(range(1,15),[result[1] for result in test_results],'-or')\naxes[0].plot(range(1,15),[result[1] for result in train_results],'-ob')\naxes[0].set_xlabel('Number of layers in decision tree (max_depth)')\naxes[0].set_ylabel('ACCURACY: Training (blue) and Test (red)')\n\naxes[1].plot(range(1,15),[result[2] for result in test_results],'-or')\naxes[1].plot(range(1,15),[result[2] for result in train_results],'-ob')\naxes[1].set_xlabel('Number of layers in decision tree (max_depth)')\naxes[1].set_ylabel('RECALL (Y=0): Training (blue) and Test (red)')\n\naxes[2].plot(range(1,15),[result[3] for result in test_results],'-or')\naxes[2].plot(range(1,15),[result[3] for result in train_results],'-ob')\naxes[2].set_xlabel('Number of layers in decision tree (max_depth)')\naxes[2].set_ylabel('RECALL (Y=1): Training (blue) and Test (red)')\n\n# Show the plots\nplt.show()\n\n\n\n\n\n\n\n\n\n# Build the optimal model and display the confusion matrix to show accuracy. Display the tree\nmodel_best = DecisionTreeClassifier(max_depth = 7)\nmodel_best = model_best.fit(x_train, y_train)\nyp_train=model.predict(x_train)\nyp_test=model.predict(x_test)\n\nprint(\"------TRAINING------\")\nconfusion_plot(y_train,yp_train)\nprint(\"------TEST------\")\nconfusion_plot(y_test,yp_test)\n\ndisplay_tree(model_best, X_class_bin, Y_class_bin)\n\n------TRAINING------\nACCURACY: 1.0\nNEGATIVE RECALL (Y=0): 1.0\nNEGATIVE PRECISION (Y=0): 1.0\nPOSITIVE RECALL (Y=1): 1.0\nPOSITIVE PRECISION (Y=1): 1.0\n[[25  0]\n [ 0  9]]\n\n\n\n\n\n\n\n\n\n------TEST------\nACCURACY: 0.6666666666666666\nNEGATIVE RECALL (Y=0): 1.0\nNEGATIVE PRECISION (Y=0): 0.6666666666666666\nPOSITIVE RECALL (Y=1): 0.0\nPOSITIVE PRECISION (Y=1): 0.0\n[[6 0]\n [3 0]]\n\n\n/home/gentry/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Now let's build a classification tree to try and predict the state in which a bike trail starts in given all numerical/binary features\nY_class = df['state1']\nX_class = df.iloc[:, 2:13]\n\nx_train, x_test, y_train, y_test = train_test_split(X_class, Y_class, test_size = 0.2, random_state = 0)\n\ntest_results=[]\ntrain_results=[]\n\nfor num_layer in range(1,15):\n    model = DecisionTreeClassifier(max_depth=num_layer)\n    model = model.fit(x_train, y_train)\n\n    yp_train=model.predict(x_train)\n    yp_test=model.predict(x_test)\n\n    test_results.append([num_layer,accuracy_score(y_test, yp_test)])\n    train_results.append([num_layer,accuracy_score(y_train, yp_train)])\n\nfig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10, 5))\n\naxes.plot(range(1,15),[result[1] for result in test_results],'-or')\naxes.plot(range(1,15),[result[1] for result in train_results],'-ob')\naxes.set_xlabel('Number of layers in decision tree (max_depth)')\naxes.set_ylabel('ACCURACY: Training (blue) and Test (red)')\n# Show the plots\nplt.show()\n\n\n\n\n\n\n\n\n\n# Build the optimal model and display the confusion matrix to show accuracy. Display the tree\nmodel_best = DecisionTreeClassifier(max_depth = 2)\nmodel_best = model_best.fit(x_train, y_train)\nyp_train=model.predict(x_train)\nyp_test=model.predict(x_test)\n\nprint(\"------TRAINING------\")\nconfusion_plot(y_train,yp_train)\nprint(\"------TEST------\")\nconfusion_plot(y_test,yp_test)\n\ndisplay_tree(model_best, X_class, Y_class)\n\n------TRAINING------\nACCURACY: 1.0\n[[10  0  0  0]\n [ 0 18  0  0]\n [ 0  0  1  0]\n [ 0  0  0  5]]\n\n\n\n\n\n\n\n\n\n------TEST------\nACCURACY: 0.4444444444444444\n[[0 1 0 0]\n [2 4 1 0]\n [0 0 0 0]\n [0 1 0 0]]"
  },
  {
    "objectID": "technical-details/data-cleaning/overview.html",
    "href": "technical-details/data-cleaning/overview.html",
    "title": "Introduction and Motivation",
    "section": "",
    "text": "Cleaning the raw trail data was a critical step in extracting meaningful insights. The descriptions of each bike trail contained a wealth of information, making data cleaning essential for conducting deeper exploratory analysis and enabling robust machine learning applications. It’s important to note that data cleaning is a dynamic and iterative process. As this project evolves, additional cleaning may be required. Below is a summary of the transformations applied to produce the cleaned dataset.\n\n\n\n\nUnpaved: Binary variable (1 = unpaved road, 0 = paved road).\nFlat: Binary variable (1 = flat road, 0 = not flat).\nWorkout: Binary variable (1 = trail designed for workouts, 0 = not designed for workouts).\nPark: Binary variable (1 = trail located in a park, 0 = not located in a park).\nRiver: Binary variable (1 = trail runs along a river, 0 = does not run along a river).\nLoop: Binary variable (1 = trail forms a loop, 0 = does not form a loop).\nSentiment: Float variable measuring the sentiment score of the trail description.\nState1: The state where the trail begins.\nState2: The state where the trail ends.\n\n\n\n\nThis dataset initially had no missing values—every cell contained data. To confirm, we used the is.na().sum() function in Python to verify the absence of null or missing values. When text-scraping trail descriptions to generate binary variables (e.g., identifying if the word “workout” was present), missing words were assumed to indicate the absence of that characteristic, and the corresponding cell was assigned a value of 0.\n\n\n\nOutliers were not a significant concern. For instance, while the C&O Towpath trail spans 184 miles—considerably longer than most other trails—removing such outliers was unnecessary. Given the limited number of bike trails in the DMV area, retaining all observations was crucial for maintaining data integrity and size.\n\n\n\nThe raw dataset contained two data types: object (trail names and descriptions) and int64 (ratings and mileage). After cleaning, the dataset included object, int64, and float64 types:\n\nObject: name, state1, state2.\nFloat64: sentiment.\nInt64: All other features.\n\nDescriptions were transformed to lowercase for consistency and ease of keyword matching. The most significant transformation involved converting descriptions into multiple binary (one-hot-encoded) features based on meaningful keywords, as described in the “New Variables” section. State information was also extracted using lists of specific locations within Virginia, Maryland, DC, and Pennsylvania, allowing us to assign values to state1 and state2. This process enabled the extraction of numerical data from text, enriching the dataset for subsequent machine learning analyses.\n\n\n\nGiven the significant right skew in the mileage distribution, normalization was applied. We used z-score normalization to scale this variable, ensuring it would not disproportionately influence machine learning models. Both normalized and unnormalized mileage distributions are provided in the ‘Code’ section below.\n\n\n\nSubsetting is unnecessary due to the already small size of the dataset."
  },
  {
    "objectID": "technical-details/data-cleaning/overview.html#overview",
    "href": "technical-details/data-cleaning/overview.html#overview",
    "title": "Introduction and Motivation",
    "section": "",
    "text": "Cleaning the raw trail data was a critical step in extracting meaningful insights. The descriptions of each bike trail contained a wealth of information, making data cleaning essential for conducting deeper exploratory analysis and enabling robust machine learning applications. It’s important to note that data cleaning is a dynamic and iterative process. As this project evolves, additional cleaning may be required. Below is a summary of the transformations applied to produce the cleaned dataset."
  },
  {
    "objectID": "technical-details/data-cleaning/overview.html#explanation-of-new-variables",
    "href": "technical-details/data-cleaning/overview.html#explanation-of-new-variables",
    "title": "Introduction and Motivation",
    "section": "",
    "text": "Unpaved: Binary variable (1 = unpaved road, 0 = paved road).\nFlat: Binary variable (1 = flat road, 0 = not flat).\nWorkout: Binary variable (1 = trail designed for workouts, 0 = not designed for workouts).\nPark: Binary variable (1 = trail located in a park, 0 = not located in a park).\nRiver: Binary variable (1 = trail runs along a river, 0 = does not run along a river).\nLoop: Binary variable (1 = trail forms a loop, 0 = does not form a loop).\nSentiment: Float variable measuring the sentiment score of the trail description.\nState1: The state where the trail begins.\nState2: The state where the trail ends."
  },
  {
    "objectID": "technical-details/data-cleaning/overview.html#managing-missing-data",
    "href": "technical-details/data-cleaning/overview.html#managing-missing-data",
    "title": "Introduction and Motivation",
    "section": "",
    "text": "This dataset initially had no missing values—every cell contained data. To confirm, we used the is.na().sum() function in Python to verify the absence of null or missing values. When text-scraping trail descriptions to generate binary variables (e.g., identifying if the word “workout” was present), missing words were assumed to indicate the absence of that characteristic, and the corresponding cell was assigned a value of 0."
  },
  {
    "objectID": "technical-details/data-cleaning/overview.html#outlier-detection-and-treatment",
    "href": "technical-details/data-cleaning/overview.html#outlier-detection-and-treatment",
    "title": "Introduction and Motivation",
    "section": "",
    "text": "Outliers were not a significant concern. For instance, while the C&O Towpath trail spans 184 miles—considerably longer than most other trails—removing such outliers was unnecessary. Given the limited number of bike trails in the DMV area, retaining all observations was crucial for maintaining data integrity and size."
  },
  {
    "objectID": "technical-details/data-cleaning/overview.html#data-type-corrections-and-formatting",
    "href": "technical-details/data-cleaning/overview.html#data-type-corrections-and-formatting",
    "title": "Introduction and Motivation",
    "section": "",
    "text": "The raw dataset contained two data types: object (trail names and descriptions) and int64 (ratings and mileage). After cleaning, the dataset included object, int64, and float64 types:\n\nObject: name, state1, state2.\nFloat64: sentiment.\nInt64: All other features.\n\nDescriptions were transformed to lowercase for consistency and ease of keyword matching. The most significant transformation involved converting descriptions into multiple binary (one-hot-encoded) features based on meaningful keywords, as described in the “New Variables” section. State information was also extracted using lists of specific locations within Virginia, Maryland, DC, and Pennsylvania, allowing us to assign values to state1 and state2. This process enabled the extraction of numerical data from text, enriching the dataset for subsequent machine learning analyses."
  },
  {
    "objectID": "technical-details/data-cleaning/overview.html#normalization-and-scaling",
    "href": "technical-details/data-cleaning/overview.html#normalization-and-scaling",
    "title": "Introduction and Motivation",
    "section": "",
    "text": "Given the significant right skew in the mileage distribution, normalization was applied. We used z-score normalization to scale this variable, ensuring it would not disproportionately influence machine learning models. Both normalized and unnormalized mileage distributions are provided in the ‘Code’ section below."
  },
  {
    "objectID": "technical-details/data-cleaning/overview.html#subsetting-data",
    "href": "technical-details/data-cleaning/overview.html#subsetting-data",
    "title": "Introduction and Motivation",
    "section": "",
    "text": "Subsetting is unnecessary due to the already small size of the dataset."
  },
  {
    "objectID": "technical-details/data-collection/overview.html",
    "href": "technical-details/data-collection/overview.html",
    "title": "Introduction and Motivation",
    "section": "",
    "text": "The primary objective of this project is to leverage data from bikewashington.org to provide actionable insights about bike paths in Washington, DC. By analyzing and presenting detailed information about these trails, we aim to help riders make informed decisions about their routes. This knowledge will enhance their preparation and contribute to safer biking experiences across the city.\n\n\n\nOur motivation lies in supporting the biking community by empowering riders to choose trails that align with their specific needs and goals. Whether for exercise, commuting, or leisure, informed decisions about bike paths can optimize the overall experience. Additionally, providing better trail information is expected to inherently enhance safety, especially for those exploring new or unfamiliar routes.\n\n\n\n\nTrail Clustering: Group similar bike trails in Washington, DC, using algorithms such as KMeans Clustering and Spectral Clustering.\nLength Prediction: Develop a regression decision tree model to predict the length of a trail based on its other qualities.\nPersonalized Recommendations: Offer tailored trail recommendations for riders of varying experience levels, addressing their unique preferences.\n\n\n\n\nAll data used in this project originates from Bike Washington. The website provides a table of detailed information about bike routes within the DMV (DC, Maryland, and Virginia) area. Specifically, it includes:\n\nTrail Length: Measured in miles.\nTrail Name: The name of each bike route.\nTrail Description: A summary of the trail’s features.\nRatings: Scores for terrain difficulty, traffic levels, and scenic beauty.\n\n\n\n\nTerrain: A score of 1 corresponds to a very flat trail, while 5 represents extremely challenging climbs.\nTraffic: A score of 1 indicates minimal traffic, while 5 suggests heavy traffic conditions.\nScenery: A score of 1 indicates a highly scenic trail, whereas 5 represents less visually appealing routes.\n\n\n\n\n\nThe cleaned data was exported to a CSV file consisting of:\n\nRows: 43 (one for each trail).\nColumns: 6 (trail name, description, mileage, terrain rating, traffic rating, and scenery rating).\nData Types:\n\nstring for trail names and descriptions.\ninteger for mileage and ratings.\n\nRegression Target: mileage\nBinary Classification Target: insert here\nMulticlass-Classification Target: location of trail (Maryland, Virginia, or DC) - found in the description"
  },
  {
    "objectID": "technical-details/data-collection/overview.html#goals",
    "href": "technical-details/data-collection/overview.html#goals",
    "title": "Introduction and Motivation",
    "section": "",
    "text": "The primary objective of this project is to leverage data from bikewashington.org to provide actionable insights about bike paths in Washington, DC. By analyzing and presenting detailed information about these trails, we aim to help riders make informed decisions about their routes. This knowledge will enhance their preparation and contribute to safer biking experiences across the city."
  },
  {
    "objectID": "technical-details/data-collection/overview.html#motivation",
    "href": "technical-details/data-collection/overview.html#motivation",
    "title": "Introduction and Motivation",
    "section": "",
    "text": "Our motivation lies in supporting the biking community by empowering riders to choose trails that align with their specific needs and goals. Whether for exercise, commuting, or leisure, informed decisions about bike paths can optimize the overall experience. Additionally, providing better trail information is expected to inherently enhance safety, especially for those exploring new or unfamiliar routes."
  },
  {
    "objectID": "technical-details/data-collection/overview.html#objectives",
    "href": "technical-details/data-collection/overview.html#objectives",
    "title": "Introduction and Motivation",
    "section": "",
    "text": "Trail Clustering: Group similar bike trails in Washington, DC, using algorithms such as KMeans Clustering and Spectral Clustering.\nLength Prediction: Develop a regression decision tree model to predict the length of a trail based on its other qualities.\nPersonalized Recommendations: Offer tailored trail recommendations for riders of varying experience levels, addressing their unique preferences."
  },
  {
    "objectID": "technical-details/data-collection/overview.html#data-source-information",
    "href": "technical-details/data-collection/overview.html#data-source-information",
    "title": "Introduction and Motivation",
    "section": "",
    "text": "All data used in this project originates from Bike Washington. The website provides a table of detailed information about bike routes within the DMV (DC, Maryland, and Virginia) area. Specifically, it includes:\n\nTrail Length: Measured in miles.\nTrail Name: The name of each bike route.\nTrail Description: A summary of the trail’s features.\nRatings: Scores for terrain difficulty, traffic levels, and scenic beauty.\n\n\n\n\nTerrain: A score of 1 corresponds to a very flat trail, while 5 represents extremely challenging climbs.\nTraffic: A score of 1 indicates minimal traffic, while 5 suggests heavy traffic conditions.\nScenery: A score of 1 indicates a highly scenic trail, whereas 5 represents less visually appealing routes."
  },
  {
    "objectID": "technical-details/data-collection/overview.html#data-structure-and-format",
    "href": "technical-details/data-collection/overview.html#data-structure-and-format",
    "title": "Introduction and Motivation",
    "section": "",
    "text": "The cleaned data was exported to a CSV file consisting of:\n\nRows: 43 (one for each trail).\nColumns: 6 (trail name, description, mileage, terrain rating, traffic rating, and scenery rating).\nData Types:\n\nstring for trail names and descriptions.\ninteger for mileage and ratings.\n\nRegression Target: mileage\nBinary Classification Target: insert here\nMulticlass-Classification Target: location of trail (Maryland, Virginia, or DC) - found in the description"
  },
  {
    "objectID": "technical-details/supervised-learning/overview.html",
    "href": "technical-details/supervised-learning/overview.html",
    "title": "Introduction and Motivation",
    "section": "",
    "text": "In this analysis, we explore the performance of regression and classification decision tree models to understand the intricate relationships within our dataset. We found that the regression tree outperformed the linear regression model, likely because decision trees do not assume any specific functional form or distribution, whereas linear regression attempts to fit a straight line through the data, which may not be suitable for complex relationships. Decision trees, by learning simple decision rules from features, are better equipped to capture the underlying patterns in the bike path dataset.\n\n\n\n\n\nWe applied z-score normalization to the mileage feature to scale it appropriately with other features.\n\n\n\n\n\nGiven the limited size of the dataset, all available features were kept, with no extraction performed.\n\n\n\n\n\nCategorical features were one-hot encoded to convert them into a binary format suitable for modeling.\n\n\n\n\n\n\n\n\nWe used the train_test_split function from sklearn to divide the dataset into training and testing sets, applying a standard 80/20 split.\n\n\n\n\n\nThe dataset was divided such that 80% was used for training, and 20% was reserved for testing."
  },
  {
    "objectID": "technical-details/supervised-learning/overview.html#data-preprocessing",
    "href": "technical-details/supervised-learning/overview.html#data-preprocessing",
    "title": "Introduction and Motivation",
    "section": "",
    "text": "We applied z-score normalization to the mileage feature to scale it appropriately with other features.\n\n\n\n\n\nGiven the limited size of the dataset, all available features were kept, with no extraction performed.\n\n\n\n\n\nCategorical features were one-hot encoded to convert them into a binary format suitable for modeling."
  },
  {
    "objectID": "technical-details/supervised-learning/overview.html#training-testing-strategy",
    "href": "technical-details/supervised-learning/overview.html#training-testing-strategy",
    "title": "Introduction and Motivation",
    "section": "",
    "text": "We used the train_test_split function from sklearn to divide the dataset into training and testing sets, applying a standard 80/20 split.\n\n\n\n\n\nThe dataset was divided such that 80% was used for training, and 20% was reserved for testing."
  },
  {
    "objectID": "technical-details/supervised-learning/overview.html#linear-regression",
    "href": "technical-details/supervised-learning/overview.html#linear-regression",
    "title": "Introduction and Motivation",
    "section": "Linear Regression",
    "text": "Linear Regression\nWe began with linear regression as a baseline to understand how well a simple linear model could fit the data. Linear regression assumes a linear relationship between the target (‘sentiment’) and the input features. We evaluated the model using two metrics:\n\nRMSE (Root Mean Squared Error): Measures the error between predicted and actual values, with a lower value being desirable.\nR²: Represents the proportion of variance explained by the model, where higher values indicate better fits.\n\nFor this analysis, we obtained: - RMSE: 0.14 - R²: 0.03\nAlthough the RMSE is low, the R² value indicates a poor fit, suggesting that a linear model is insufficient for capturing the underlying relationships in the data. We decided to proceed with more complex models."
  },
  {
    "objectID": "technical-details/supervised-learning/overview.html#regression-tree",
    "href": "technical-details/supervised-learning/overview.html#regression-tree",
    "title": "Introduction and Motivation",
    "section": "Regression Tree",
    "text": "Regression Tree\nNext, we applied a regression tree, which is non-parametric and can dynamically fit the data by learning decision rules. We fine-tuned the model by testing various max_depth hyperparameters, which control the depth of the tree. We found that a max_depth of 2 minimized the testing error while avoiding overfitting.\n\nOptimal hyperparameter: max_depth = 2\nTraining RMSE: 0.11\nTesting RMSE: 0.048 (lower than the linear regression model)\n\nThe regression tree significantly outperformed linear regression in terms of RMSE, indicating that the model was better suited to capture the underlying patterns in the data."
  },
  {
    "objectID": "technical-details/supervised-learning/overview.html#binary-classification-tree",
    "href": "technical-details/supervised-learning/overview.html#binary-classification-tree",
    "title": "Introduction and Motivation",
    "section": "Binary Classification Tree",
    "text": "Binary Classification Tree\nAfter the regression task, we focused on a binary classification problem: predicting whether a bike path is a loop (1) or not (0). Given the poor R² from the linear regression, we chose to avoid logistic regression and instead used a decision tree for classification. We tuned the max_depth hyperparameter and found that a value of 7 yielded the best performance.\n\nOptimal hyperparameter: max_depth = 7\nAccuracy: 78%\nConfusion Matrix:\n\nNegative recall: 100%\nNegative precision: 75%\nPositive recall: 33%\nPositive precision: 100%\n\n\nThe model performed well in terms of accuracy, but the confusion matrix revealed that it frequently predicted the non-loop class (0), likely due to class imbalance in the dataset. This bias resulted in a low positive recall."
  },
  {
    "objectID": "technical-details/supervised-learning/overview.html#multiclass-classification-tree",
    "href": "technical-details/supervised-learning/overview.html#multiclass-classification-tree",
    "title": "Introduction and Motivation",
    "section": "Multiclass Classification Tree",
    "text": "Multiclass Classification Tree\nFinally, we aimed to predict the ‘state1’ variable, which represents multiple categories. We evaluated the model by testing various max_depth values to find the optimal setting. We selected max_depth = 2 based on its performance.\n\nOptimal hyperparameter: max_depth = 2\nTest Accuracy: 44%\n\nAlthough the model outperformed random guessing, with an accuracy of 44%, it was not highly predictive. The confusion matrix indicated that the model tended to predict the most prevalent class correctly, but struggled with the other categories."
  },
  {
    "objectID": "technical-details/supervised-learning/overview.html#discussion",
    "href": "technical-details/supervised-learning/overview.html#discussion",
    "title": "Introduction and Motivation",
    "section": "Discussion",
    "text": "Discussion\n\n1. Result Interpretation\n\nThe regression tree emerged as the best-performing model, with a testing RMSE of 0.048, which indicates a good fit. However, further testing with additional data would be important for validating its robustness.\nThe binary classification tree performed well overall, with 78% accuracy, but the confusion matrix highlighted issues with class imbalance. The model heavily favored predicting non-loop paths, which reduced its utility in predicting the loop class.\nThe multiclass classification model achieved an accuracy of 44%, which is marginally better than guessing randomly. It often predicted the most common class, but failed to predict the other categories accurately. More data and improved feature engineering would likely enhance the performance of this model.\n\n\n\n2. Model Performance Comparison\n\nAmong all models tested, the regression tree offered the best performance with the lowest RMSE. The binary classification tree showed promising accuracy but suffered from class imbalance issues. The multiclass model’s performance was the weakest, highlighting the need for better predictive features or more data.\n\n\n\n3. Insights Gained\n\nThe regression tree is the most reliable model for this dataset, as it can better capture non-linear relationships. For classification tasks, particularly binary classification, addressing class imbalance and tuning the model further is crucial. The multiclass model, while slightly better than random, would benefit from more data and better feature selection to improve predictive accuracy."
  },
  {
    "objectID": "index.html#summary",
    "href": "index.html#summary",
    "title": "Analyzing Bike Routes in Washington, DC",
    "section": "Summary",
    "text": "Summary\nWashington DC is a leader in urban cycling infrastructure, with an expansive network of bike lanes and trails supporting eco-friendly commuting. However, DC’s trails are not only for commuting within the city but also numerous options for purely recreational use. In the confides of a large city these options for recreation can be extremly popular, so a deeper understanding of bike route utilization, accessibility, and safety are imperative. This project focuses on scraping, analyzing, and visualizing data about DC’s bike routes to identify patterns and trends through clustering and classification. The insights gained can guide city planners in optimizing infrastructure, improving safety, and promoting cycling as a sustainable mode of transportation."
  },
  {
    "objectID": "index.html#significance",
    "href": "index.html#significance",
    "title": "Analyzing Bike Routes in Washington, DC",
    "section": "Significance",
    "text": "Significance\nCycling is integral to sustainable urban mobility, offering benefits such as reduced carbon emissions, improved public health, and decreased traffic congestion. By analyzing cycling routes, we can uncover patterns of use, gaps in infrastructure, and safety concerns, enabling data-driven decision-making for a greener and safer DC."
  },
  {
    "objectID": "index.html#intended-audience",
    "href": "index.html#intended-audience",
    "title": "Analyzing Bike Routes in Washington, DC",
    "section": "Intended Audience",
    "text": "Intended Audience\n\nBike enthusiasts in Washington, DC\nData professionals looking to replicate analysis in other cities"
  },
  {
    "objectID": "index.html#key-topics",
    "href": "index.html#key-topics",
    "title": "Analyzing Bike Routes in Washington, DC",
    "section": "Key Topics",
    "text": "Key Topics\n\nK-Means Clustering\nDimensionality Reduction (PCA/t-SNE)\nRegression Decision Tree Classificaiton\nPredictive Models\nData Visualization"
  },
  {
    "objectID": "index.html#related-work",
    "href": "index.html#related-work",
    "title": "Analyzing Bike Routes in Washington, DC",
    "section": "Related Work",
    "text": "Related Work\n\nUrban Cycling Studies: Research linking bike infrastructure to cycling adoption and safety.\nGeospatial Data Science: Use of clustering algorithms for route categorization and optimization in other urban contexts.\nMachine Learning in Mobility: Classification techniques applied to transportation data to understand user behavior and needs.\nLocal Reports: Existing reports on cycling trends in Washington, DC, such as those from DDOT and Capital Bikeshare."
  },
  {
    "objectID": "index.html#research-questions",
    "href": "index.html#research-questions",
    "title": "Analyzing Bike Routes in Washington, DC",
    "section": "Research Questions",
    "text": "Research Questions\n\nHow can clustering techniques help categorize bike routes based on usage, distance, location, or ratings?\nWhich factors are the most important in clustering of bike routes?\nIs it possible to classify bike routes with existing data?\nWhat insights can be drawn about the existing routes in developing more routes as the city grows?\nWhat data would make this clustering and classification more robust?"
  },
  {
    "objectID": "index.html#literature-review",
    "href": "index.html#literature-review",
    "title": "Analyzing Bike Routes in Washington, DC",
    "section": "Literature Review",
    "text": "Literature Review\nIn the past decade, urban cycling infrastructure has garnered attention due to the relevance in addressing environmental sustainability concerns. Cycling offers a low-cost, sustainable mode of transportation that reduces greenhouse gas emissions, mitigates traffic congestion, and promotes physical activity. Understanding the current landscape of research on this topic is crucial for identifying gaps in knowledge and expand on them. This literature review aims to harmonize key findings, methodologies, and trends have shaped the current understanding of this topic area.\n“How to Use Selenium to Web-Scrape with Example”1 provides a step-by-step guide on using Selenium, a Python library, for web scraping tasks, focusing on extracting NBA player salary data from Hoopshype. Selenium automates web browsers, allowing for efficient data collection from websites that may be otherwise difficult to scrape through traditional methods. Selenium’s advantage lies in its ability to interact with dynamic web pages, which may load content via JavaScript. This method is particularly useful for collecting structured data from websites that do not provide APIs or straightforward access to information, such as the site we are interested in gathering our data from. This article is relevant to our study as it demonstrates the basic workflow for setting up and using Selenium for web scraping. The same techniques of web driver installation, XPath usage, and data extraction will be applicable for scraping bike route information from the provided websites. Additionally, the iterative process of scraping multiple pages and aggregating data aligns with the need to collect comprehensive datasets for clustering and classification in this project.\nIn the article “Visual Exploration of Cycling Semantics with GPS Trajectory Data”2, the authors address the need for a comprehensive system to analyze cycling semantics from both the cyclist’s and the road’s perspectives. By utilizing large-scale GPS trajectory and road network data, the authors propose VizCycSemantics, a visual analytic system that aims to uncover hidden patterns in cycling behaviors and moving characteristics along road segments. While this paper gets bogged down with technical jargon about GPS data and challenges, they present some very interesting points on clustering. The VizCycSemantics system uses Latent Dirichlet Allocation (LDA) to extract cycling topics—representing cyclist behaviors—and k-means++ clustering to identify groups of similar cyclists and road segments. This research is particularly relevant to our project, as it provides a proven framework for analyzing cycling data through clustering and topic modeling. While our base approach will differ significantly, our goal of uncovering patterns in cycling routes and behaviors aligns well with their study.\nChapter 9 of “Capital Dilemma”3 addresses bicycling trends and policies in the DC area since 1990. The study of cycling trends in the Washington, DC metropolitan area provides essential insights into the growing role of cycling in urban mobility and infrastructure planning. The expansion of bike lanes, along with innovative programs and policies, has significantly increased cycling levels in the region, particularly within the urban core of Washington, DC, Arlington, and Alexandria. As highlighted, cycling levels have risen in tandem with the development of bike-friendly infrastructure, such as on-street bike lanes and off-street shared-use paths, though challenges remain in terms of accessibility and inclusivity. This literature is highly relevant to our project, where we aim to analyze and classify bike routes in Washington, DC. Understanding the spatial distribution of bike lanes and their relationship with cyclist behavior in various neighborhoods offers a valuable framework for our clustering and classification efforts.\nThe article “Machine Learning Approaches to Bike-Sharing Systems: A Systematic Literature Review”4 details numerous applications of machine learning techniques within the sphere of bike-sharing systems (BSS). It stresses the importance of these systems in the modern era, highlighting their role in reducing carbon emissions, improving transportation accessibility, and influencing the overall transportation culture of a city. The paper reviews 35 studies from 2015 to 2019, aiming to evaluate the performance of various machine learning techniques applied to BSS while also identifying challenges and proposing future research directions. The methodology used to evaluate the machine learning methods is the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) Framework. Key findings from the paper include the high accuracy with which random forests and gradient boosting machines predicted bike availability and demand trends. Other techniques, such as decision trees and deep learning, were useful for understanding trip patterns and user segmentation. Deep learning, in particular, is becoming more prevalent, as neural networks are capable of efficiently handling complex datasets. Finally, clustering techniques were applied to analyze station usage patterns and trends. The paper concludes that, through a combination of machine learning, transportation engineering, and planning, future efforts should focus on developing machine learning models that are easily interpretable and transferable to various cities. Another goal is to leverage real-time data to optimize BSS instantaneously.\nThe article “Learning to Cluster Urban Areas: Two Competitive Approaches and an Empirical Validation”5 compares two clustering methodologies to effectively group urban areas with similar characteristics. The two approaches introduced are Deep Modularity Networks (DMON) and a traditional graph-based clustering method. DMON is a neural network approach designed to optimize cluster modularity. Specifically, it graphically represents urban areas and connects them to other areas that share similar spatial or economic traits. The network maximizes modularity while adapting to different situations for greater flexibility. The traditional graph method, on the other hand, relies on classical algorithms like spectral clustering. Although these algorithms also maximize modularity, they underperform in terms of adaptability, scalability, and other areas. Through empirical validation, the authors demonstrate that DMON outperforms the traditional graph method in terms of performance, processing efficiency, and utility. One application of DMON discussed in the paper is its use for transportation planning. This clustering method helps identify critical transportation nodes and corridors, facilitating more efficient transit design. However, DMON has some limitations, particularly in terms of interpretability. Deep learning often produces outputs that are difficult for non-experts to understand, which could hinder the urban planning process and lead to stagnation. Despite this, the paper demonstrates the effectiveness of clustering methods in addressing urban environmental issues.\nUnlike the previous two papers, this research, “A Taxonomy of Machine Learning Clustering Algorithms, Challenges, and Future Realms”6, offers a more comprehensive examination of clustering algorithms. The paper categorizes various clustering algorithms based on their methodologies and use cases, providing insight into which algorithms are best suited for specific situations. More specifically, the paper focuses on five different types of clustering algorithms: partitioning-based clustering, hierarchical clustering, density-based clustering, model-based clustering, and graph-based clustering. Partitioning-based clustering is best used in applications such as customer segmentation and urban planning. Hierarchical clustering is more appropriate for social network analysis or gene expression studies. Density-based clustering is suitable for spatial analysis and transportation planning. Model-based clustering is commonly applied to problems involving images and text. Finally, graph-based clustering excels in social network detection and geospatial analysis. Regardless of the problem, all clustering methods have their inherent limitations and should be used carefully. Future directions for clustering algorithms include combining two or more algorithms to leverage their strengths, as well as exploring automatic hyperparameter tuning to ensure optimal performance for specific problems. Clustering is an invaluable tool for solving real-world problems, but it is essential to choose the right algorithm based on the specific context."
  },
  {
    "objectID": "index.html#about-us",
    "href": "index.html#about-us",
    "title": "Analyzing Bike Routes in Washington, DC",
    "section": "About Us",
    "text": "About Us\n\n\n\nGentry Lamb\nGentry Lamb is a Graduate Student at Georgetown University pursuing a Master’s in Data Science and Analytics. He received a Bachelor’s in Operations Research in 2024 from the United States Air Force Academy in Colorado Springs, CO. He was also commissioned into the U.S. Air Force as a 2nd Lt and will be attending Pilot Training at Vance AFB in Oklahoma after graduating from Georgetown. After his time in the Air Force, he looks forward to working as a data scientist or operations analyst.\nEducation: - 2024: United States Air Force Academy (USAFA) - B.S. Operations Research\n- 2025: Georgetown University - M.S. Data Science and Analytics (Current)\n\n\n\nGentry Lamb\n\n\n\n\n\n\n\nChase Clemence\nChase Clemence is currently a graduate student at Georgetown University pursuing a Master’s of Science in Data Science & Analytics. He received a Bachelor’s of Science in Operations Research from the United States Air Force Academy in 2024, commissioning as a 2nd Lieutenant. After obtaining his degree, he will head to Goodfellow AFB in San Angelo, Texas, to start training as a Military Intelligence Officer in the United States Air Force. Following his Air Force career, he aspires to earn an MBA and work in industry. He hopes having a background in data science and business will make him an effective leader in the civilian sector.\nEducation: - 2024: United States Air Force Academy (USAFA) - B.S. Operations Research\n- 2025: Georgetown University - M.S. Data Science and Analytics (Current)\n\n\n\nChase Clemence"
  },
  {
    "objectID": "technical-details/llm-usage-log.html",
    "href": "technical-details/llm-usage-log.html",
    "title": "LLM usage log",
    "section": "",
    "text": "This page can serve as a “catch-all” for LLM use cases that don’t involve content creation, such as reformatting your own ideas, commenting code that you wrote, or proofreading text, PDF summarization.\nLLM tools were used in the following way for the tasks below"
  },
  {
    "objectID": "technical-details/llm-usage-log.html#brainstorming",
    "href": "technical-details/llm-usage-log.html#brainstorming",
    "title": "LLM usage log",
    "section": "Brainstorming",
    "text": "Brainstorming\n\nOnce we decided on a topic, ChatGPT was used to help with refining our research questions and narrow in on topics for related work.1"
  },
  {
    "objectID": "technical-details/llm-usage-log.html#writing",
    "href": "technical-details/llm-usage-log.html#writing",
    "title": "LLM usage log",
    "section": "Writing:",
    "text": "Writing:\n\nProofreading and improving grammar in the literature reviews.2\nImproved content we wrote to improve overall flow and idea expression.3"
  },
  {
    "objectID": "technical-details/llm-usage-log.html#code",
    "href": "technical-details/llm-usage-log.html#code",
    "title": "LLM usage log",
    "section": "Code:",
    "text": "Code:\n\nUsed ChatGPT to help with error that was faced when accessing the ChromeDriver for Selenium. It suggested that we add the 4 lines of code adjusting chrome options.4"
  }
]