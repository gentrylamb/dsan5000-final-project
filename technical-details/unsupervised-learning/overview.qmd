# Introduction and Motivation

The primary objective of this analysis is to explore and identify meaningful groupings within a dataset of bike routes in Washington, DC, based on features like distance, ratings, sentiment, and route descriptions. By applying clustering techniques, we aim to uncover hidden patterns that can offer insights into the structure of bike routes across the city. To aid in visualizing these patterns, we also conduct dimensionality reduction using PCA and t-SNE. These methods help reduce the complexity of the high-dimensional data, allowing for clearer visualization and interpretation of the clustering results. The analysis involves testing three clustering algorithms—K-Means, DBSCAN, and Agglomerative Clustering—and comparing their performance in terms of cluster quality and relevance to the underlying features of the routes. Ultimately, the goal is to identify clusters that can inform urban planning and biking route optimization in a practical context.

# Overview of Methods

This analysis employs three clustering algorithms to identify groups within the bike routes dataset, along with dimensionality reduction techniques to visualize the results effectively:

- **PCA (Principal Component Analysis) and t-SNE (t-Distributed Stochastic Neighbor Embedding)**: Used to reduce the dimensionality of the data. PCA compresses the features into principal components, capturing the most important variance in the dataset, while t-SNE further reduces the data to two dimensions, making it easier to visualize the clusters. 
- **K-Means Clustering**: K-Means is a partitioning-based algorithm that assigns data points into a predefined number of clusters by iterating between assigning points to the nearest centroid and updating the centroids based on these assignments. The number of clusters (`n_clusters`) is determined by evaluating the silhouette score, a metric that measures how well-separated the clusters are.
- **DBSCAN (Density-Based Spatial Clustering of Applications with Noise)**: DBSCAN is a density-based clustering algorithm that groups data points based on their proximity to each other and the density of their surroundings. Unlike K-Means, DBSCAN does not require specifying the number of clusters in advance. It relies on two hyperparameters: `eps` (the maximum distance between two points to be considered neighbors) and `min_samples` (the minimum number of points required to form a cluster). DBSCAN also identifies noise points, which are labeled as -1.
- **Agglomerative Clustering**: Agglomerative Clustering is a hierarchical method that builds clusters by iteratively merging the closest pairs of clusters. The number of clusters (`n_clusters`) is specified as a hyperparameter, and the algorithm outputs cluster labels for each data point. Agglomerative Clustering produces a hierarchical tree (dendrogram) that shows how clusters are merged, which can help understand the relationships between different groupings.